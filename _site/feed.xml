<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-06-01T15:06:08+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Sina Ahmadi’s Personal Page</title><subtitle>Sina Ahmadi's Personal Page</subtitle><author><name>Sina Ahmadi</name></author><entry><title type="html">Summer datathon in Dagstuhl</title><link href="http://localhost:4000/posts/summer-datathon-in-dagstuhl.html" rel="alternate" type="text/html" title="Summer datathon in Dagstuhl" /><published>2019-05-18T00:00:00+01:00</published><updated>2019-05-18T00:00:00+01:00</updated><id>http://localhost:4000/posts/summer-datathon-in-dagstuhl</id><content type="html" xml:base="http://localhost:4000/posts/summer-datathon-in-dagstuhl.html">&lt;p&gt;Last week, I participated in the &lt;a href=&quot;https://datathon2019.linguistic-lod.org/&quot; target=&quot;_blank&quot;&gt;3rd Summer Datathon on Linguistic Linked Open Data (SD-LLOD-19)&lt;/a&gt; which was held in the &lt;a href=&quot;https://www.dagstuhl.de/&quot; target=&quot;_blank&quot;&gt;Schloss Dagstuhl – Leibniz Center for Informatics&lt;/a&gt;, Wadern, Germany. As my first datathon where I was a tutor, it was such an amazing experience that I would like to write about here.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/pictures/Dagstuhl/summerdatathon.jpg&quot; style=&quot;width:50%&quot; align=&quot;middle&quot; alt=&quot;3rd Summer Datathon on Linguistic Linked Open Data&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            3rd Summer Datathon on Linguistic Linked Open Data (11-17 May 2019)
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Schloss Dagstuhl (or Dagstuhl Castle) is a historical amazing place where seminars and scientific events are regularly held in informatics and computer science. It is located in the middle of a forest where the nearest big city, Trier, has a distance of 56 km (&lt;a href=&quot;https://goo.gl/maps/J4uNszY3BYzf7uJC8&quot; target=&quot;_blank&quot;&gt;see on the map&lt;/a&gt;). According to the &lt;a href=&quot;https://www.leibniz-gemeinschaft.de/en/institutes-museums/einrichtungen/lzi/&quot; target=&quot;_blank&quot;&gt;Leibniz Center for Informatics&lt;/a&gt; website:&lt;/p&gt;

&lt;div class=&quot;ml-3&quot;&gt;
&lt;p class=&quot;text-muted&quot;&gt;
Since 1990, Schloss Dagstuhl, Leibniz Center for Informatics has organized informatics conferences of the highest scientific caliber. It also promotes and supports continuing and advanced academic education and the transfer of knowledge between academia and industry. The center fosters world-class informatics research by bringing internationally renowned researchers and promising young scientists from universities together with those from industrial research laboratories. Dagstuhl’s comprehensive offerings are utilized by over 3,000 scientists from all over the world each year. 
&lt;/p&gt;
&lt;/div&gt;

&lt;h2 id=&quot;arrival&quot;&gt;Arrival&lt;/h2&gt;

&lt;p&gt;Arrived in Germany on May 11 from Dublin, I stayed the night in Frankfurt, a city that I liked so much. Luckily, the same evening when I arrived, there were a bunch of interesting events going on in the city on the occasion of the Museum Night 2019.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/pictures/Dagstuhl/frankfurtMuseumNight2019.jpg&quot; style=&quot;width:100%&quot; align=&quot;middle&quot; alt=&quot;Frankfurt Museum Night 2019&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Frankfurt on May 11, Museum Night 2019. 
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Reaching Schloss Dagstuhl can be challenging as there is not much public transport directly to the place from major cities. Therefore, taking a taxi seems to be the easiest option to get there. Personally, I set out for &lt;a href=&quot;https://goo.gl/maps/L5FET32DYs5x6szH6&quot; target=&quot;_blank&quot;&gt;Sankt Wendel&lt;/a&gt;, a town in north-eastern Saarland, where the participants were waited for in the train station. One of the local organizers kindly picked us up to the venue which took roughly half an hour. Having said that, such a remote and relaxed location in the countryside made the visit even more particular. No matter how far away, it is really worth it!&lt;/p&gt;

&lt;p&gt;Something great that I experienced from the very first moments that I met other participants in the Sankt Wendel train station was how cool they were! &lt;b&gt;I really enjoyed every single moment that I spent with all of them who are now my friends&lt;/b&gt;…&lt;/p&gt;

&lt;h2 id=&quot;and-wow&quot;&gt;And wow!&lt;/h2&gt;

&lt;p&gt;Yes. That was exactly how I was astonished when I visited such a mysterious and beautiful place surrounded by greenery! Everything was so well organized and prepared with meticulous care. I’d say Schloss Dagstuhl is not only a complex but a small city having a church, a library, several seminar rooms and guest houses, awesome foods (oh Lord!), a music room, even a sauna and a fitness room. Visiting every corner of the place is so joyful, seeing all those collections, paintings and artworks everywhere. Can you believe that even the tables are allocated to the participants using an algorithm to ensure that the participants meet each other at least once during their stay?!&lt;/p&gt;

&lt;div class=&quot;card-columns&quot;&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190517_183835.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190517_183009.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190516_172931.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190514_230407.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190514_212120.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190514_160940.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190512_190522.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190516_172948.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/IMG_20190517_000232.jpg&quot; /&gt;
    &lt;/div&gt;
    
&lt;/div&gt;

&lt;p&gt;There were a few music instruments in the music room, a piano, guitars and a violin, which turned our evening meetings more pleasant listening to the live music played by the talented participants. I also had the pleasure to play Bach’s Minuet in G major with &lt;a href=&quot;http://jogracia.url.ph/web/&quot;&gt;Dr. Jorge Gracia&lt;/a&gt;. By the way, I promise there were more talented people playing other instruments more professionally and beautifully than me (they know whom I’m talking about!).&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
&lt;h5 style=&quot;text-align:center;&quot;&gt;
&lt;iframe width=&quot;560&quot; height=&quot;330&quot; src=&quot;https://www.youtube.com/embed/ZWBkxNYnH9w&quot; frameborder=&quot;0&quot; allow=&quot;accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/h5&gt;
&lt;div class=&quot;card-body bg-light&quot;&gt;
    &lt;div class=&quot;card-text&quot;&gt;
      Bach's Minuet in G major in Schloss Dagstuhl (Thanks Patricia for shooting the video)
    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;linguistic-linked-open-data&quot;&gt;Linguistic Linked Open Data&lt;/h2&gt;

&lt;p&gt;As the title suggests, the main objective of our gathering in Dagstuhl was to participate in a datathon on linguistic linked open data. With an increasing importance in data representation and data modelling, semantic web and linked data has attracted interest from various research communities in academia and industry. In this datathon, we addressed a wide range of topics in linked open data with a particular attention to its linguistic applications. In addition to the presentations by the speakers, a few practical tools such as &lt;a href=&quot;http://openrefine.org/&quot; target=&quot;_blank&quot;&gt;OpenRefine&lt;/a&gt; and &lt;a href=&quot;https://protege.stanford.edu/&quot; target=&quot;_blank&quot;&gt;Protégé&lt;/a&gt; were introduced. I also introduced &lt;a href=&quot;https://uld.pages.insight-centre.org/naisc/&quot; target=&quot;_blank&quot;&gt;Naisc&lt;/a&gt;, a data linking tool developped at our &lt;a href=&quot;https://nuig.insight-centre.org/uld/&quot; target=&quot;_blank&quot;&gt;Unit for Linguistic Data&lt;/a&gt; at &lt;a href=&quot;https://nuig.insight-centre.org/&quot; target=&quot;_blank&quot;&gt;Insight Center&lt;/a&gt;.&lt;/p&gt;

&lt;table align=&quot;center&quot; class=&quot;table table-bordered table-hover table-condensed&quot;&gt;
&lt;thead&gt;&lt;tr&gt;
&lt;th title=&quot;Field #2&quot;&gt;Project name&lt;/th&gt;
&lt;th title=&quot;Field #3&quot;&gt;Tutor&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
    &lt;td&gt;Redefining the Dictionary Fabric - the case from industry&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://www.dfki.de/~declerck/&quot; target=&quot;_blank&quot;&gt;Thierry Declerck&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Linked Linguistic Corpus Data&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;http://www.acoli.informatik.uni-frankfurt.de/&quot; target=&quot;_blank&quot;&gt;Christian Fäth, Christian Chiarcos&lt;/a&gt;, &lt;a href=&quot;http://jogracia.url.ph/web/&quot; target=&quot;_blank&quot;&gt;Jorge Gracia&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;TED talks transformation to LOD (🏆 participant votes)&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;http://andon.tchechmedjiev.eu/&quot; target=&quot;_blank&quot;&gt;Andon Tchechmedjiev&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Modeling Cherokee lexical-morphological data&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;http://aksw.org/BettinaKlimek.html&quot; target=&quot;_blank&quot;&gt;Bettina Klimek&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Historical texts; linking multiple annotations: Corpora&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;http://ionov.me/&quot; target=&quot;_blank&quot;&gt;Max Ionov&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;a href=&quot;https://sinaahmadi.github.io/posts/resource-population-using-wikidata-and-wiktionary.html&quot; target=&quot;_blank&quot;&gt;Ontology Conversion and Resource Population&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;Me&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Modelling Akkadian dictionary data with ontolex-lemon using lexicog&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;http://mayor2.dia.fi.upm.es/oeg-upm/index.php/en/phdstudents/360-jbosque/index.html&quot; target=&quot;_blank&quot;&gt;Julia Bosque Gil&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;e-science corpus metadata as Linked Open Data&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://www.insight-centre.org/users/alessandro-adamou&quot; target=&quot;_blank&quot;&gt;Alessandro Adamou&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This datathon was wonderfully organized by &lt;a href=&quot;http://acoli.informatik.uni-frankfurt.de/&quot; target=&quot;_blank&quot;&gt;Dr. Christian Chiarcos&lt;/a&gt;, &lt;a href=&quot;http://john.mccr.ae/&quot; target=&quot;_blank&quot;&gt;Dr. John Philip McCrae&lt;/a&gt; and &lt;a href=&quot;http://jogracia.url.ph/web/&quot; target=&quot;_blank&quot;&gt;Dr. Jorge Gracia&lt;/a&gt;. Here is a photo of the organizers and the tutors all together:&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/pictures/Dagstuhl/organizers.jpg&quot; style=&quot;width:100%&quot; align=&quot;middle&quot; alt=&quot;Organizes and tutors of the datathon&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Organizers and tutors of the datathon
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Regarding our project, we created a tool for populating resources which were provided by the participants of our group, using Wikidata and Wiktionary, and converting the produced resources into the &lt;a href=&quot;https://www.w3.org/community/ontolex/wiki/Final_Model_Specification&quot; target=&quot;_blank&quot;&gt;OntoLex&lt;/a&gt; ontology. A full documentation of our project can be found &lt;a href=&quot;https://sinaahmadi.github.io/posts/resource-population-using-wikidata-and-wiktionary.html&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/pictures/Dagstuhl/group6_datathon.jpg&quot; style=&quot;width:100%&quot; align=&quot;middle&quot; alt=&quot;Frankfurt Museum Night 2019&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Our team in the datathon
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;other-activities&quot;&gt;Other activities&lt;/h2&gt;

&lt;p&gt;In addition to our heavy daily programs, we had a couple of cultural visits to the famous Castle of Dagstuhl (15 minutes walk) and the historical city of Trier (45 minutes by bus). Here are a few photos of the Dagstuhl castle.&lt;/p&gt;

&lt;div class=&quot;card-columns&quot;&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/Castle/IMG_20190514_194144.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/Castle/IMG_20190514_194337.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/Castle/IMG_20190514_194416.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/Castle/IMG_20190514_194455.jpg&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div class=&quot;card&quot;&gt;
        &lt;img class=&quot;card-img-top&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sinaahmadi.github.io/master/docs/pictures/Dagstuhl/Castle/IMG_20190514_194233.jpg&quot; /&gt;
    &lt;/div&gt;
    
&lt;/div&gt;

&lt;h2 id=&quot;finally&quot;&gt;Finally&lt;/h2&gt;

&lt;p&gt;Although I learnt a lot of new things and acquired new experiences as a tutor in such an awesome datathon, what mattered more than anything else to me was the new friends that I made. This event let me make new friends who are also brilliant researchers. We spent a lot of good moments together, full of joy and happiness and fruitful discussions. I strongly believe that the &lt;b&gt;friendship&lt;/b&gt; is the best outcome of such events.&lt;/p&gt;

&lt;p&gt;Following this event, I participated in the &lt;a href=&quot;http://2019.ldk-conf.org&quot; target=&quot;_blank&quot;&gt;Language, Data and Knowledge&lt;/a&gt; conference in Leipzig. In additio to the main conference, I participated in the &lt;a href=&quot;https://tiad2019.unizar.es/&quot; target=&quot;_blank&quot;&gt;TIAD 2019 workshop&lt;/a&gt; and community meetings of &lt;a href=&quot;http://2019.ldk-conf.org/ontolex-face-2-face-meeting/&quot; target=&quot;_blank&quot;&gt;OntoLex&lt;/a&gt; and &lt;a href=&quot;https://wiki.dbpedia.org/meetings/Leipzig2019&quot; target=&quot;_blank&quot;&gt;DBpedia&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If you are interested in the datathon and would like to know about the next event, check out the &lt;a href=&quot;https://datathon2019.linguistic-lod.org/&quot; target=&quot;_blank&quot;&gt;official website&lt;/a&gt;. All the tweets related to the datathon can be found &lt;a href=&quot;https://twitter.com/hashtag/SDLLOD19?src=hash&quot; target=&quot;_blank&quot;&gt;here&lt;/a&gt; as well.&lt;/p&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 29 May 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="Linked Data" /><category term="Datathon" /><category term="NLP" /><summary type="html">Last week, I participated in the 3rd Summer Datathon on Linguistic Linked Open Data (SD-LLOD-19) which was held in the Schloss Dagstuhl – Leibniz Center for Informatics, Wadern, Germany. As my first datathon where I was a tutor, it was such an amazing experience that I would like to write about here. 3rd Summer Datathon on Linguistic Linked Open Data (11-17 May 2019) Schloss Dagstuhl (or Dagstuhl Castle) is a historical amazing place where seminars and scientific events are regularly held in informatics and computer science. It is located in the middle of a forest where the nearest big city, Trier, has a distance of 56 km (see on the map). According to the Leibniz Center for Informatics website: Since 1990, Schloss Dagstuhl, Leibniz Center for Informatics has organized informatics conferences of the highest scientific caliber. It also promotes and supports continuing and advanced academic education and the transfer of knowledge between academia and industry. The center fosters world-class informatics research by bringing internationally renowned researchers and promising young scientists from universities together with those from industrial research laboratories. Dagstuhl’s comprehensive offerings are utilized by over 3,000 scientists from all over the world each year. Arrival Arrived in Germany on May 11 from Dublin, I stayed the night in Frankfurt, a city that I liked so much. Luckily, the same evening when I arrived, there were a bunch of interesting events going on in the city on the occasion of the Museum Night 2019. Frankfurt on May 11, Museum Night 2019. Reaching Schloss Dagstuhl can be challenging as there is not much public transport directly to the place from major cities. Therefore, taking a taxi seems to be the easiest option to get there. Personally, I set out for Sankt Wendel, a town in north-eastern Saarland, where the participants were waited for in the train station. One of the local organizers kindly picked us up to the venue which took roughly half an hour. Having said that, such a remote and relaxed location in the countryside made the visit even more particular. No matter how far away, it is really worth it! Something great that I experienced from the very first moments that I met other participants in the Sankt Wendel train station was how cool they were! I really enjoyed every single moment that I spent with all of them who are now my friends… And wow! Yes. That was exactly how I was astonished when I visited such a mysterious and beautiful place surrounded by greenery! Everything was so well organized and prepared with meticulous care. I’d say Schloss Dagstuhl is not only a complex but a small city having a church, a library, several seminar rooms and guest houses, awesome foods (oh Lord!), a music room, even a sauna and a fitness room. Visiting every corner of the place is so joyful, seeing all those collections, paintings and artworks everywhere. Can you believe that even the tables are allocated to the participants using an algorithm to ensure that the participants meet each other at least once during their stay?! There were a few music instruments in the music room, a piano, guitars and a violin, which turned our evening meetings more pleasant listening to the live music played by the talented participants. I also had the pleasure to play Bach’s Minuet in G major with Dr. Jorge Gracia. By the way, I promise there were more talented people playing other instruments more professionally and beautifully than me (they know whom I’m talking about!). Bach's Minuet in G major in Schloss Dagstuhl (Thanks Patricia for shooting the video) Linguistic Linked Open Data As the title suggests, the main objective of our gathering in Dagstuhl was to participate in a datathon on linguistic linked open data. With an increasing importance in data representation and data modelling, semantic web and linked data has attracted interest from various research communities in academia and industry. In this datathon, we addressed a wide range of topics in linked open data with a particular attention to its linguistic applications. In addition to the presentations by the speakers, a few practical tools such as OpenRefine and Protégé were introduced. I also introduced Naisc, a data linking tool developped at our Unit for Linguistic Data at Insight Center. Project name Tutor Redefining the Dictionary Fabric - the case from industry Thierry Declerck Linked Linguistic Corpus Data Christian Fäth, Christian Chiarcos, Jorge Gracia TED talks transformation to LOD (🏆 participant votes) Andon Tchechmedjiev Modeling Cherokee lexical-morphological data Bettina Klimek Historical texts; linking multiple annotations: Corpora Max Ionov Ontology Conversion and Resource Population Me Modelling Akkadian dictionary data with ontolex-lemon using lexicog Julia Bosque Gil e-science corpus metadata as Linked Open Data Alessandro Adamou This datathon was wonderfully organized by Dr. Christian Chiarcos, Dr. John Philip McCrae and Dr. Jorge Gracia. Here is a photo of the organizers and the tutors all together: Organizers and tutors of the datathon Regarding our project, we created a tool for populating resources which were provided by the participants of our group, using Wikidata and Wiktionary, and converting the produced resources into the OntoLex ontology. A full documentation of our project can be found here. Our team in the datathon Other activities In addition to our heavy daily programs, we had a couple of cultural visits to the famous Castle of Dagstuhl (15 minutes walk) and the historical city of Trier (45 minutes by bus). Here are a few photos of the Dagstuhl castle. Finally Although I learnt a lot of new things and acquired new experiences as a tutor in such an awesome datathon, what mattered more than anything else to me was the new friends that I made. This event let me make new friends who are also brilliant researchers. We spent a lot of good moments together, full of joy and happiness and fruitful discussions. I strongly believe that the friendship is the best outcome of such events. Following this event, I participated in the Language, Data and Knowledge conference in Leipzig. In additio to the main conference, I participated in the TIAD 2019 workshop and community meetings of OntoLex and DBpedia. If you are interested in the datathon and would like to know about the next event, check out the official website. All the tweets related to the datathon can be found here as well. Last updated on 29 May 2019.</summary></entry><entry><title type="html">Resource population using Wikidata and Wiktionary</title><link href="http://localhost:4000/posts/resource-population-using-wikidata-and-wiktionary.html" rel="alternate" type="text/html" title="Resource population using Wikidata and Wiktionary" /><published>2019-05-16T00:00:00+01:00</published><updated>2019-05-16T00:00:00+01:00</updated><id>http://localhost:4000/posts/resource-population-using-wikidata-and-wiktionary</id><content type="html" xml:base="http://localhost:4000/posts/resource-population-using-wikidata-and-wiktionary.html">&lt;p&gt;There are an increasing number of lexical resources available online which are machine-friendly and can be accessed by linked data techniques.&lt;/p&gt;

&lt;p&gt;In this repository, we provide a program which collects linguistic information for a given word, in raw text or triples, and converts the collected data to Lemon-OntoLex ontology. The current resources being used are &lt;a href=&quot;https://www.wikidata.org/wiki/Wikidata:Main_Page&quot; target=&quot;_blank&quot;&gt;Wikidata&lt;/a&gt; and &lt;a href=&quot;https://www.wiktionary.org/&quot; target=&quot;_blank&quot;&gt;Wiktionary&lt;/a&gt;. However, any resource which can be accessed via a SPARQL endpoint can be used in this program.&lt;/p&gt;

&lt;p&gt;The following image shows information for the Italian word “acroterio” in Wikidata.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sparql4respop/master/wikidata.png&quot; style=&quot;width:90%&quot; align=&quot;middle&quot; alt=&quot;artchitecture&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
           &quot;acroterio&quot;(italian) as an example of how data are represented in Wikidata.
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h2 id=&quot;how-does-it-work&quot;&gt;How does it work?&lt;/h2&gt;

&lt;p&gt;Given a list of words in text or in RDF, this program collects all the relevant information in Wikidata and Wiktionary.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;https://raw.githubusercontent.com/sinaahmadi/sparql4respop/master/architecture.png&quot; style=&quot;width:60%&quot; align=&quot;middle&quot; alt=&quot;artchitecture&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            The architecture of resource enrichment
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;change-categories&quot;&gt;Change categories&lt;/h3&gt;

&lt;p&gt;In order to collect data in a specific domain, you can add your desired category to the &lt;code class=&quot;highlighter-rouge&quot;&gt;subjects&lt;/code&gt;. Note that this may affect the performance of the queries as it will take longer to check all the domains.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; subjects = {&quot;architecture&quot;:&quot;Q12271&quot;, &quot;archeology&quot;: &quot;Q10855079&quot;, &quot;law&quot; : &quot;Q7748&quot;, &quot;legal science&quot; : &quot;Q382995&quot;, &quot;social issue&quot; : &quot;Q1920219&quot;, &quot;jurisprudence&quot; : &quot;Q4932206&quot;, &quot;rule&quot; : &quot;Q1151067&quot;, &quot;Economy&quot; : &quot;Q159810&quot;, &quot;Economics&quot; : &quot;Q8134&quot;, &quot;labour law&quot; : &quot;Q628967&quot;, &quot;human action&quot; : &quot;Q451967&quot;, &quot;legal concept&quot; : &quot;Q2135465&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;include-external-ontologies&quot;&gt;Include external ontologies&lt;/h3&gt;

&lt;p&gt;If you would like to link your Lemon-Ontolex data to an external ontology, you can use the &lt;code class=&quot;highlighter-rouge&quot;&gt;ontolex:reference&lt;/code&gt; property. One of the example given datasets provide the URIs in a tab-separated format.&lt;/p&gt;

&lt;h3 id=&quot;conversion-to-lemon-ontolex&quot;&gt;Conversion to Lemon-OntoLex&lt;/h3&gt;

&lt;p&gt;The conversion is done using predefined templates for each part of each part of the data, such as, entry description, &lt;a href=&quot;https://www.w3.org/2016/05/ontolex/#variation-translation-vartrans&quot; target=&quot;_blank&quot;&gt;vatrans&lt;/a&gt;, linguistic information (pos, gender etc.). The following figure illustrated the Lemon-OntoLex core model.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.w3.org/2016/05/ontolex/Lemon_OntoLex_Core.png&quot; alt=&quot;Lemon-OntoLex&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;limitations&quot;&gt;Limitations&lt;/h2&gt;

&lt;p&gt;Please note that the current version of the program only takes into account very specific information and is not creating a fine-grained Lemon-Ontolex representation. For instance, only “OntoLex:LexicalEntry” for representing entries are used (no &lt;code class=&quot;highlighter-rouge&quot;&gt;components&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Our codes are available at &lt;a href=&quot;https://github.com/sinaahmadi/sparql4respop&quot; target=&quot;_blank&quot;&gt;https://github.com/sinaahmadi/sparql4respop&lt;/a&gt;&lt;/p&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 21 May 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="Linked Data" /><category term="SPARQL" /><category term="Resource population" /><category term="NLP" /><summary type="html">There are an increasing number of lexical resources available online which are machine-friendly and can be accessed by linked data techniques. In this repository, we provide a program which collects linguistic information for a given word, in raw text or triples, and converts the collected data to Lemon-OntoLex ontology. The current resources being used are Wikidata and Wiktionary. However, any resource which can be accessed via a SPARQL endpoint can be used in this program. The following image shows information for the Italian word “acroterio” in Wikidata. &quot;acroterio&quot;(italian) as an example of how data are represented in Wikidata. How does it work? Given a list of words in text or in RDF, this program collects all the relevant information in Wikidata and Wiktionary. The architecture of resource enrichment Change categories In order to collect data in a specific domain, you can add your desired category to the subjects. Note that this may affect the performance of the queries as it will take longer to check all the domains. subjects = {&quot;architecture&quot;:&quot;Q12271&quot;, &quot;archeology&quot;: &quot;Q10855079&quot;, &quot;law&quot; : &quot;Q7748&quot;, &quot;legal science&quot; : &quot;Q382995&quot;, &quot;social issue&quot; : &quot;Q1920219&quot;, &quot;jurisprudence&quot; : &quot;Q4932206&quot;, &quot;rule&quot; : &quot;Q1151067&quot;, &quot;Economy&quot; : &quot;Q159810&quot;, &quot;Economics&quot; : &quot;Q8134&quot;, &quot;labour law&quot; : &quot;Q628967&quot;, &quot;human action&quot; : &quot;Q451967&quot;, &quot;legal concept&quot; : &quot;Q2135465&quot;} Include external ontologies If you would like to link your Lemon-Ontolex data to an external ontology, you can use the ontolex:reference property. One of the example given datasets provide the URIs in a tab-separated format. Conversion to Lemon-OntoLex The conversion is done using predefined templates for each part of each part of the data, such as, entry description, vatrans, linguistic information (pos, gender etc.). The following figure illustrated the Lemon-OntoLex core model. Limitations Please note that the current version of the program only takes into account very specific information and is not creating a fine-grained Lemon-Ontolex representation. For instance, only “OntoLex:LexicalEntry” for representing entries are used (no components). Our codes are available at https://github.com/sinaahmadi/sparql4respop Last updated on 21 May 2019.</summary></entry><entry><title type="html">Text pre-processing in command-line</title><link href="http://localhost:4000/posts/text-pre-processing-with-bash.html" rel="alternate" type="text/html" title="Text pre-processing in command-line" /><published>2019-04-16T00:00:00+01:00</published><updated>2019-04-16T00:00:00+01:00</updated><id>http://localhost:4000/posts/text-pre-processing-with-bash</id><content type="html" xml:base="http://localhost:4000/posts/text-pre-processing-with-bash.html">&lt;p&gt;Whether your are a newbie or professional in natural language processing or data mining, text pre-processing is a task that you need to go through at some point. Although there is a plethora of libraries which do the pre-processing of your text perfectly, none of them may have &lt;strong&gt;power, simplicity&lt;/strong&gt; and &lt;strong&gt;flexibility&lt;/strong&gt; that the command-line programs provide to you. In this tutorial, a few simple but essential programs are introduced for text pre-processing in &lt;a href=&quot;https://en.wikipedia.org/wiki/Command-line_interface&quot; target=&quot;_blank&quot;&gt;&lt;strong&gt;command-line&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;What we mean by &lt;strong&gt;text pre-processing&lt;/strong&gt; is the normalisation of text by removing special characters (e.g. punctuation marks, non-Unicode characters etc.), tokens or changing the whole structure of the text for a specific purpose (e.g. adding &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;eos&amp;gt;&lt;/code&gt; to the end of sentences for training neural networks). In other words, whatever required to prepare a text file to be processed is a part of text pre-processing. Later, we will discuss text processing tasks such as &lt;u&gt;counting unique words&lt;/u&gt; in a document, &lt;u&gt;sorting words by frequency&lt;/u&gt;, &lt;u&gt;removing stop words&lt;/u&gt;, &lt;u&gt;retrieving specific text structures&lt;/u&gt;.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/command_line_text_preprocessing.png&quot; style=&quot;width:75%&quot; align=&quot;middle&quot; alt=&quot;Text pre-processing using command-line&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Text pre-processing is fun with command-line.
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Obviously, for one problem there may be more than one solution. However, in this tutorial, only a few techniques and programs are introduced. It will be up to you, your preference and the requirements of your tasks to decide which command fits better to your problem. Personally, I love the command-line and how each program can be used as a piece of puzzle, thanks to &lt;strong&gt;pipes&lt;/strong&gt;, to solve sophisticated problems, particularly where processing time and performance matter.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;System setup&lt;/strong&gt;: The commands in this tutorial have been tested on GNU bash, version 5.0.2(1)-release (x86_64-apple-darwin18.2.0). You will normally have no problem running them on any Unix-based operating system. If you are a Windows user, the best solution is to start using a Linux-based open-source operating system like &lt;a href=&quot;https://www.ubuntu.com/&quot; target=&quot;_blank&quot;&gt;Ubuntu&lt;/a&gt; (seriously, do it!). Otherwise, you can simply install &lt;a href=&quot;https://www.cygwin.com/&quot; target=&quot;_blank&quot;&gt;Cygwin&lt;/a&gt; which lets you enjoy GNU in you Windows, &lt;em&gt;somehow&lt;/em&gt;!&lt;/p&gt;

&lt;p&gt;If you are not familiar with command-line, particularly Bash–the command language interpreter for the GNU operating system, you should learn the basic concepts, features and commands. This &lt;a href=&quot;https://tiswww.case.edu/php/chet/bash/bashref.html&quot; target=&quot;_blank&quot;&gt;reference manual&lt;/a&gt; may be useful. Recall that you may use the &lt;code class=&quot;highlighter-rouge&quot;&gt;man&lt;/code&gt; command to display the user manual of any command.&lt;/p&gt;

&lt;h2 id=&quot;text-preprocessing-commands&quot;&gt;Text-preprocessing commands&lt;/h2&gt;

&lt;p&gt;If you are interested in executing the commands in practice, you can download &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;this text file&lt;/a&gt; in your working directory and see how each command works. Our sample text is very noisy; it contains html tags, indented paragraphs, multiple unnecessary newlines, spaces and tokens. &lt;strong&gt;Our goal&lt;/strong&gt; is to clean this sample text by getting rid of the noisy stuff.&lt;/p&gt;

&lt;h3 id=&quot;text-reading&quot;&gt;Text reading&lt;/h3&gt;

&lt;p&gt;The very first step of any task in text (pre-)processing is text reading. We will see later in this tutorial that some commands, like &lt;code class=&quot;highlighter-rouge&quot;&gt;wc&lt;/code&gt;, take care of the text reading without requiring us to do any further commands for reading.&lt;/p&gt;

&lt;h4 id=&quot;cat&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt;&lt;/h4&gt;
&lt;h5 id=&quot;syntax-cat-options-filenames&quot;&gt;Syntax: &lt;code class=&quot;highlighter-rouge&quot;&gt;cat [options] [filenames]&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt; command (short for “concatenate“) is one of the most frequent commands which not only allows us to read files, but also create, display and concatenate them.&lt;/p&gt;

&lt;p&gt;The following command prints out the whole file content in your command-line:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You may use the &lt;code class=&quot;highlighter-rouge&quot;&gt;less&lt;/code&gt; command which lets you scroll through the file without having all the file content displayed on the command-line. &lt;strong&gt;Don’t forget to use pipes&lt;/strong&gt;, i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt; whenever you want to use the output of a command as the input of another command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | less&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To exit the viewing window press &lt;code class=&quot;highlighter-rouge&quot;&gt;q&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You may write your file content in a new file like:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; new_noisy_text.txt
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; new_noisy_text.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The difference between &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&amp;gt;&lt;/code&gt; is that the first one overwrites the file if it already exists while the latter one keeps the content untouched and appends to the existing file.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt; can also turn your command-line into a basic text editor as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; quick_note.txt
This is a quick note to remember that I should call the clinic asap.
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;By using &lt;code class=&quot;highlighter-rouge&quot;&gt;cat &amp;gt; quick_note.txt&lt;/code&gt;, you are creating a new file and allowing &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt; to write whatever you type in the command-line as the content of your file. Once you are done with typing, &lt;code class=&quot;highlighter-rouge&quot;&gt;cntrl-d&lt;/code&gt; saves the content and returns the command-line to its normal functionality.&lt;/p&gt;

&lt;p&gt;The awesomeness of &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt; is not limited to these! You can concatenate multiple files into one as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;semester1_2019_results.txt semester2_2019_results.txt &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 2019_results.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This way, the content of those two files is merged into a new file called &lt;em&gt;2019_results.txt&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&quot;head-and-tail&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;head&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tail&lt;/code&gt;&lt;/h4&gt;
&lt;h5 id=&quot;syntax-head-options-files-tail-options-files&quot;&gt;Syntax: &lt;code class=&quot;highlighter-rouge&quot;&gt;head [options] [file(s)]&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;tail [options] [file(s)]&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;Sometimes you only want to take a look at how the content of a file looks like. &lt;code class=&quot;highlighter-rouge&quot;&gt;head&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tail&lt;/code&gt; are two commands which allow us to view a certain number of lines of a file, respectively at the beginning and the end.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;head noisy_text.txt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;There is an interesting option &lt;code class=&quot;highlighter-rouge&quot;&gt;-n&lt;/code&gt; which lets us to specify how many lines be displayed. The default value is 10 lines.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;head &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 2  noisy_text.txt
   0001193125-12-075999.txt : 20120224 0001193125-12-075999.hdr.sgml :
   20120224 20120223203324 ACCESSION NUMBER: 0001193125-12-075999
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tail &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 2 noisy_text.txt
  84. javascript:void&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  85. javascript:void&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;0&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;head&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tail&lt;/code&gt; allow further manoeuvres by using them in various orders with pipes and different options. Suppose that you have file containing 1000 lines and you would like to read lines 286 to 300. One way to do so is the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;head &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 300 noisy_text.txt | tail &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; 14&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;get-a-block-of-text-with-awk&quot;&gt;Get a block of text with &lt;code class=&quot;highlighter-rouge&quot;&gt;awk&lt;/code&gt;&lt;/h5&gt;

&lt;p&gt;But what if you only want a specific range of lines in your file? Well, you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;awk&lt;/code&gt; as the following:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= first_line &amp;amp;&amp;amp; NR &amp;lt;= last_line'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;where the &lt;em&gt;first_line&lt;/em&gt; and &lt;em&gt;last_line&lt;/em&gt; should be replaced by the line range that you are interested in. For instance, the lines 48 to 51 in our sample file are:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= 818 &amp;amp;&amp;amp; NR &amp;lt;= 820'&lt;/span&gt;

         Atlantic City Electric Company, which was incorporated &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;New Jersey &lt;span class=&quot;k&quot;&gt;in
         &lt;/span&gt;1924.
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;awk&lt;/code&gt; is a very useful command in text (pre)processing that we will discuss later.&lt;/p&gt;

&lt;h3 id=&quot;conversion-to-utf-8-with-iconv&quot;&gt;Conversion to UTF-8 with &lt;code class=&quot;highlighter-rouge&quot;&gt;iconv&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;syntax-iconv--f-source-encoding-code--t-target-encoding-code--inputfile---outputfile&quot;&gt;Syntax: &lt;code class=&quot;highlighter-rouge&quot;&gt;iconv -f source-encoding-code -t target-encoding-code &amp;lt; inputfile  &amp;gt; outputfile&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;Although nowadays &lt;a href=&quot;https://www.unicode.org/&quot; target=&quot;_blank&quot;&gt;Unicode standard&lt;/a&gt; is the default encoding of most programs and on the web, there are still texts for which older encodings such as ISO 8859 and Windows-1252 were used and therefore, converting them is necessary. For this purpose, there is a program called &lt;code class=&quot;highlighter-rouge&quot;&gt;iconv&lt;/code&gt; which converts your text from an encoding to another one. The syntax of &lt;code class=&quot;highlighter-rouge&quot;&gt;iconv&lt;/code&gt; is shown above; Change the &lt;code class=&quot;highlighter-rouge&quot;&gt;source-encoding-code&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;target-encoding-code&lt;/code&gt; to the encoding of your source text and your desired output encoding, respectively.&lt;/p&gt;

&lt;p&gt;Our &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;sample text file&lt;/a&gt; is encoded in UTF-8. The following is an example to convert “crépuscule” from UTF-8 to ISO-8859-15:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;crépuscule&quot;&lt;/span&gt; | iconv &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; UTF-8 &lt;span class=&quot;nt&quot;&gt;-t&lt;/span&gt; ISO-8859-15
cr?puscule
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Recall that &lt;code class=&quot;highlighter-rouge&quot;&gt;echo&lt;/code&gt; displays a text on standard output.&lt;/p&gt;

&lt;p&gt;Any characters that &lt;code class=&quot;highlighter-rouge&quot;&gt;iconv&lt;/code&gt; does not know how to convert will be replaced with question marks. This may not be good when conversion accuracy matters. However, when dealing with large number of files, I personally prefer having a bunch of &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;s to prevent any text reading errors!&lt;/p&gt;

&lt;h3 id=&quot;replace-characters-using-tr&quot;&gt;Replace characters using &lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;syntax-tr-options-set1-set2&quot;&gt;Syntax: &lt;code class=&quot;highlighter-rouge&quot;&gt;tr [options] [set1] [set2]&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;Replacing or removing specific characters is also a part of text pre-processing. For instance, unnecessary spaces or newlines may not be welcomed for some tasks. &lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt;, abbreviation of &lt;em&gt;translate&lt;/em&gt; or &lt;em&gt;transliterate&lt;/em&gt;, is a very useful command which deals with such cases.&lt;/p&gt;

&lt;p&gt;Suppose that you have the following text in Greek, where &lt;code class=&quot;highlighter-rouge&quot;&gt;;&lt;/code&gt; is normally used as &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;, and you want to replace &lt;code class=&quot;highlighter-rouge&quot;&gt;;&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Πώς θέλετε να πληρώσετε;&quot;&lt;/span&gt; | tr &lt;span class=&quot;s2&quot;&gt;&quot;;&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;?&quot;&lt;/span&gt;
Πώς θέλετε να πληρώσετε?
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;or, replacing spaces by newlines:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amount of plastic in ocean is worse than we thought, study says&quot;&lt;/span&gt; | tr &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
Amount
of
plastic
&lt;span class=&quot;k&quot;&gt;in
&lt;/span&gt;ocean
is
worse
than
we
thought,
study
says
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Replacing characters can also be done with a sequence of characters as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amount of plastic in ocean is worse than we thought, study says&quot;&lt;/span&gt; | tr &lt;span class=&quot;s2&quot;&gt;&quot;iplo&quot;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;abnu&quot;&lt;/span&gt;
Amuunt uf bnastac an ucean as wurse than we thuught, study says
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case, &lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt; simply translates a character in the first set “iplo” to its corresponding one in the second set “abnu”.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt; also supports character sets such as &lt;code class=&quot;highlighter-rouge&quot;&gt;a-z&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;A-Z&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;0-9&lt;/code&gt; to represent lower case alphabets, upper case alphabets and digits, respectively:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amount of plastic in ocean is worse than we thought, study says&quot;&lt;/span&gt; | tr &lt;span class=&quot;s1&quot;&gt;'a-z'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'A-Z'&lt;/span&gt;
AMOUNT OF PLASTIC IN OCEAN IS WORSE THAN WE THOUGHT, STUDY SAYS
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;What if we want to replace multiple occurrences of a character by another character? For instance, line 340 to 363 in the &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;sample text file&lt;/a&gt; contain multiple spaces that we would like to be removed and be replaced by one. This can be done with the &lt;code class=&quot;highlighter-rouge&quot;&gt;-s&lt;/code&gt; option of &lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= 340  &amp;amp;&amp;amp; NR &amp;lt;= 350'&lt;/span&gt;

                                  &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3]PART I

                                 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;4]Item 1.
                             -       Business      3

                                 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;5]Item 1A.
                           -       Risk Factors      23

                                 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;6]Item 1B.
                    -       Unresolved Staff Comments      37

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The text looks like the following after removing multiple spaces and newlines:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= 340  &amp;amp;&amp;amp; NR &amp;lt;= 350'&lt;/span&gt; | tr &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt; | tr &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;

 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;3]PART I
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;4]Item 1.
 - Business 3
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;5]Item 1A.
 - Risk Factors 23
 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;6]Item 1B.
 - Unresolved Staff Comments 37

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To delete all the occurrences of a character, you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;tr -d [set]&lt;/code&gt; which acts like &lt;code class=&quot;highlighter-rouge&quot;&gt;tr [set] &quot;&quot;&lt;/code&gt;:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Amount of plastic in ocean is worse than we thought, study says&quot;&lt;/span&gt; | tr &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;o&quot;&lt;/span&gt;
Amunt f plastic &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;cean is wrse than we thught, study says
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To discover more interesting options, try &lt;code class=&quot;highlighter-rouge&quot;&gt;man tr&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&quot;remove-html-tags-or-anything-between-tags&quot;&gt;Remove HTML tags (or anything between tags)&lt;/h3&gt;

&lt;p&gt;The commands that we introduced so far were used directly over the text with simple patterns. What if we need to deal with more sophisticated text patterns? This is where regular expressions (regex) come in!&lt;/p&gt;

&lt;p&gt;Regex allow us to access parts of a text based on the rules that we define. In some ways, a regex is analogous to a database query or a semantic query. It’s a query to extract information from raw text!&lt;/p&gt;

&lt;p&gt;Let’s take a look at our &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;sample text file&lt;/a&gt; where lines 1215 to 1220 contain HTML code (look like an HTML table):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= 1215 &amp;amp;&amp;amp; NR &amp;lt;= 1220'&lt;/span&gt;
   &lt;span class=&quot;nv&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;font-family: Times New Roman;&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
   &amp;lt;&lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;)&lt;/span&gt;&amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td &lt;span class=&quot;nv&quot;&gt;valign&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;bottom&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;lt;font &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
   &amp;lt;&lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td &lt;span class=&quot;nv&quot;&gt;valign&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;bottom&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;lt;font
   &lt;span class=&quot;nv&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;font-family: Times New Roman;&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
   &amp;lt;&lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td &lt;span class=&quot;nv&quot;&gt;valign&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;bottom&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;align&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;right&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&amp;lt;font
   &lt;span class=&quot;nv&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;font-family: Times New Roman;&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Let’s assume that we want to remove the tags, i.e. anything between &amp;lt; and &amp;gt; and we only want to keep whatever enclosed by tags. To do so, we create a regular expression which looks for anything starting with a &amp;lt; and proceeds until it gets to a &amp;gt;; the regex includes anything between those two characters, except a &amp;gt;. This regex is: &lt;code class=&quot;highlighter-rouge&quot;&gt;/&amp;lt;[^&amp;gt;]*&amp;gt;/&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For this problem, we use &lt;a href=&quot;https://www.perl.org/&quot; target=&quot;_blank&quot;&gt;Perl&lt;/a&gt; which is a programming language frequently used in text processing thanks to its facilities. It can also be used in the command-line just like other commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'NR &amp;gt;= 1215 &amp;amp;&amp;amp; NR &amp;lt;= 1220'&lt;/span&gt; | perl &lt;span class=&quot;nt&quot;&gt;-0777&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pe&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/&amp;lt;[^&amp;gt;]*&amp;gt;//gs'&lt;/span&gt;
   &lt;span class=&quot;nv&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;font-family: Times New Roman;&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
   &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &amp;amp;nbsp&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &amp;lt;font
   &lt;span class=&quot;nv&quot;&gt;style&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;font-family: Times New Roman;&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;class&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;_mt&quot;&lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;There are a few details that we should know.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-0777&lt;/code&gt; option lets us to slurp the file and feed all the lines to Perl in one go.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;-pe&lt;/code&gt; is composed of two flags: &lt;code class=&quot;highlighter-rouge&quot;&gt;e&lt;/code&gt; which allows us to specify the Perl code to be run and, &lt;code class=&quot;highlighter-rouge&quot;&gt;-p&lt;/code&gt; flag processes the file line by line.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;s/[set1]/[set2]/&lt;/code&gt; is the substitution operator which substitutes &lt;code class=&quot;highlighter-rouge&quot;&gt;[set1]&lt;/code&gt; by &lt;code class=&quot;highlighter-rouge&quot;&gt;[set2]&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/g&lt;/code&gt; is the global flag which does the matching over the whole text.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/s&lt;/code&gt; treats the string as a single long line (only difference is that &lt;code class=&quot;highlighter-rouge&quot;&gt;\n&lt;/code&gt; is also included when &lt;code class=&quot;highlighter-rouge&quot;&gt;.&lt;/code&gt; is used).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another example with Perl. The following regular expression replaces newlines with more than two occurrences with only two newlines. This can also be done with the previous commands that we introduced, like &lt;code class=&quot;highlighter-rouge&quot;&gt;tr&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;perl &lt;span class=&quot;nt&quot;&gt;-0777&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pe&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/(\n[ ]*){2,}/\n\n/gmi'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;https://perldoc.perl.org/perlrequick.html&quot; target=&quot;_blank&quot;&gt;Here&lt;/a&gt; you can learn more about the fascinating functionalities of regular expressions in Perl. Most of the text editors make it easy to test and debug regular expressions and visualizing them. There are also many websites for the same purpose, such as &lt;a href=&quot;https://regex101.com/&quot; target=&quot;_blank&quot;&gt;https://regex101.com/&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;text-split-with-split&quot;&gt;Text split with &lt;code class=&quot;highlighter-rouge&quot;&gt;split&lt;/code&gt;&lt;/h3&gt;
&lt;h4 id=&quot;syntax-split-options-filename-prefix&quot;&gt;Syntax: &lt;code class=&quot;highlighter-rouge&quot;&gt;split [options] filename prefix&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;We perviously mentioned how to merge files using &lt;code class=&quot;highlighter-rouge&quot;&gt;cat&lt;/code&gt;. What if we want to split a huge text file into smaller parts? This can be done with &lt;code class=&quot;highlighter-rouge&quot;&gt;split&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;split&lt;/code&gt; allows us to split a file based on the number of lines with &lt;code class=&quot;highlighter-rouge&quot;&gt;-l&lt;/code&gt; option and based on size with &lt;code class=&quot;highlighter-rouge&quot;&gt;-b&lt;/code&gt;. Let’s split our &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;sample text file&lt;/a&gt; into smaller files containing 500 lines each one:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;split &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt; 500 noisy_text.txt
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;tree
&lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
├── noisy_text.txt
├── xaa
├── xab
├── xac
└── xad

0 directories, 5 files
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;wrapping-up&quot;&gt;Wrapping up&lt;/h3&gt;

&lt;p&gt;How your text is to be pre-processed depends on the content of your file and your pre-processing purpose. You should know what the noisy stuff are and the issues that should be cleaned or normalised.&lt;/p&gt;

&lt;p&gt;Suppose that we need the following steps to clean our &lt;a href=&quot;http://localhost:4000/docs/tutorials/noisy_text.txt&quot; target=&quot;_blank&quot;&gt;sample text file&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Remove HTML tags (&lt;code class=&quot;highlighter-rouge&quot;&gt;perl -0777 -pe 's/&amp;lt;[^&amp;gt;]*&amp;gt;//gs'&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Remove noisy non-alphanumeric content  (&lt;code class=&quot;highlighter-rouge&quot;&gt;perl -0777 -pe 's/^[\S]*[^\w\s][\S]*$//gmi'&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Remove unwanted tokens, like &lt;code class=&quot;highlighter-rouge&quot;&gt;javascript:void(0);&lt;/code&gt;, and characters (&lt;code class=&quot;highlighter-rouge&quot;&gt;awk '{gsub(/^.*javascript.*$/,&quot;\n&quot;); print }'&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;awk '{gsub(/&amp;amp;nbsp;/,&quot; &quot;); print }'&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Following the techniques introduced earlier in this tutorial, we clean the sample text as follows:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;cat &lt;/span&gt;noisy_text.txt | awk &lt;span class=&quot;s1&quot;&gt;'{gsub(/^ */,&quot;&quot;); print }'&lt;/span&gt; | tr &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot; &quot;&lt;/span&gt; | perl &lt;span class=&quot;nt&quot;&gt;-0777&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pe&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/^[\S]*[^\w\s][\S]*$//gmi'&lt;/span&gt; |  perl &lt;span class=&quot;nt&quot;&gt;-0777&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pe&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/&amp;lt;[^&amp;gt;]*&amp;gt;//gs'&lt;/span&gt; | awk &lt;span class=&quot;s1&quot;&gt;'{gsub(/^.*javascript.*$/,&quot;\n&quot;); print }'&lt;/span&gt; | awk &lt;span class=&quot;s1&quot;&gt;'{gsub(/&amp;amp;nbsp;/,&quot; &quot;); print }'&lt;/span&gt; | perl &lt;span class=&quot;nt&quot;&gt;-0777&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-pe&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'s/(\n[ ]*){2,}/\n\n/gmi'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; cleaned_noisy_text.txt
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;a href=&quot;http://localhost:4000/docs/tutorials/cleaned_noisy_text.txt&quot; target=&quot;_blank&quot;&gt;This is&lt;/a&gt; how this long command cleans our sample text file like a charm!&lt;/p&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 28 April 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="NLP" /><category term="Text processing" /><category term="Bash" /><category term="Tutorial" /><summary type="html">Whether your are a newbie or professional in natural language processing or data mining, text pre-processing is a task that you need to go through at some point. Although there is a plethora of libraries which do the pre-processing of your text perfectly, none of them may have power, simplicity and flexibility that the command-line programs provide to you. In this tutorial, a few simple but essential programs are introduced for text pre-processing in command-line. What we mean by text pre-processing is the normalisation of text by removing special characters (e.g. punctuation marks, non-Unicode characters etc.), tokens or changing the whole structure of the text for a specific purpose (e.g. adding &amp;lt;eos&amp;gt; to the end of sentences for training neural networks). In other words, whatever required to prepare a text file to be processed is a part of text pre-processing. Later, we will discuss text processing tasks such as counting unique words in a document, sorting words by frequency, removing stop words, retrieving specific text structures. Text pre-processing is fun with command-line. Obviously, for one problem there may be more than one solution. However, in this tutorial, only a few techniques and programs are introduced. It will be up to you, your preference and the requirements of your tasks to decide which command fits better to your problem. Personally, I love the command-line and how each program can be used as a piece of puzzle, thanks to pipes, to solve sophisticated problems, particularly where processing time and performance matter. System setup: The commands in this tutorial have been tested on GNU bash, version 5.0.2(1)-release (x86_64-apple-darwin18.2.0). You will normally have no problem running them on any Unix-based operating system. If you are a Windows user, the best solution is to start using a Linux-based open-source operating system like Ubuntu (seriously, do it!). Otherwise, you can simply install Cygwin which lets you enjoy GNU in you Windows, somehow! If you are not familiar with command-line, particularly Bash–the command language interpreter for the GNU operating system, you should learn the basic concepts, features and commands. This reference manual may be useful. Recall that you may use the man command to display the user manual of any command. Text-preprocessing commands If you are interested in executing the commands in practice, you can download this text file in your working directory and see how each command works. Our sample text is very noisy; it contains html tags, indented paragraphs, multiple unnecessary newlines, spaces and tokens. Our goal is to clean this sample text by getting rid of the noisy stuff. Text reading The very first step of any task in text (pre-)processing is text reading. We will see later in this tutorial that some commands, like wc, take care of the text reading without requiring us to do any further commands for reading. cat Syntax: cat [options] [filenames] The cat command (short for “concatenate“) is one of the most frequent commands which not only allows us to read files, but also create, display and concatenate them. The following command prints out the whole file content in your command-line: $ cat noisy_text.txt You may use the less command which lets you scroll through the file without having all the file content displayed on the command-line. Don’t forget to use pipes, i.e. | whenever you want to use the output of a command as the input of another command. $ cat noisy_text.txt | less To exit the viewing window press q. You may write your file content in a new file like: $ cat noisy_text.txt &amp;gt; new_noisy_text.txt $ cat noisy_text.txt &amp;gt;&amp;gt; new_noisy_text.txt The difference between &amp;gt; and &amp;gt;&amp;gt; is that the first one overwrites the file if it already exists while the latter one keeps the content untouched and appends to the existing file. cat can also turn your command-line into a basic text editor as follows: $ cat &amp;gt; quick_note.txt This is a quick note to remember that I should call the clinic asap. $ By using cat &amp;gt; quick_note.txt, you are creating a new file and allowing cat to write whatever you type in the command-line as the content of your file. Once you are done with typing, cntrl-d saves the content and returns the command-line to its normal functionality. The awesomeness of cat is not limited to these! You can concatenate multiple files into one as follows: $ cat semester1_2019_results.txt semester2_2019_results.txt &amp;gt; 2019_results.txt This way, the content of those two files is merged into a new file called 2019_results.txt. head and tail Syntax: head [options] [file(s)], tail [options] [file(s)] Sometimes you only want to take a look at how the content of a file looks like. head and tail are two commands which allow us to view a certain number of lines of a file, respectively at the beginning and the end. $ head noisy_text.txt There is an interesting option -n which lets us to specify how many lines be displayed. The default value is 10 lines. $ head -n 2 noisy_text.txt 0001193125-12-075999.txt : 20120224 0001193125-12-075999.hdr.sgml : 20120224 20120223203324 ACCESSION NUMBER: 0001193125-12-075999 $ tail -n 2 noisy_text.txt 84. javascript:void(0); 85. javascript:void(0); $ head and tail allow further manoeuvres by using them in various orders with pipes and different options. Suppose that you have file containing 1000 lines and you would like to read lines 286 to 300. One way to do so is the following: $ head -n 300 noisy_text.txt | tail -n 14 Get a block of text with awk But what if you only want a specific range of lines in your file? Well, you can use awk as the following: $ awk 'NR &amp;gt;= first_line &amp;amp;&amp;amp; NR &amp;lt;= last_line' where the first_line and last_line should be replaced by the line range that you are interested in. For instance, the lines 48 to 51 in our sample file are: $ cat noisy_text.txt | awk 'NR &amp;gt;= 818 &amp;amp;&amp;amp; NR &amp;lt;= 820' Atlantic City Electric Company, which was incorporated in New Jersey in 1924. $ awk is a very useful command in text (pre)processing that we will discuss later. Conversion to UTF-8 with iconv Syntax: iconv -f source-encoding-code -t target-encoding-code &amp;lt; inputfile &amp;gt; outputfile Although nowadays Unicode standard is the default encoding of most programs and on the web, there are still texts for which older encodings such as ISO 8859 and Windows-1252 were used and therefore, converting them is necessary. For this purpose, there is a program called iconv which converts your text from an encoding to another one. The syntax of iconv is shown above; Change the source-encoding-code and the target-encoding-code to the encoding of your source text and your desired output encoding, respectively. Our sample text file is encoded in UTF-8. The following is an example to convert “crépuscule” from UTF-8 to ISO-8859-15: $ echo &quot;crépuscule&quot; | iconv -f UTF-8 -t ISO-8859-15 cr?puscule $ Recall that echo displays a text on standard output. Any characters that iconv does not know how to convert will be replaced with question marks. This may not be good when conversion accuracy matters. However, when dealing with large number of files, I personally prefer having a bunch of ?s to prevent any text reading errors! Replace characters using tr Syntax: tr [options] [set1] [set2] Replacing or removing specific characters is also a part of text pre-processing. For instance, unnecessary spaces or newlines may not be welcomed for some tasks. tr, abbreviation of translate or transliterate, is a very useful command which deals with such cases. Suppose that you have the following text in Greek, where ; is normally used as ?, and you want to replace ; with ?: $ echo &quot;Πώς θέλετε να πληρώσετε;&quot; | tr &quot;;&quot; &quot;?&quot; Πώς θέλετε να πληρώσετε? $ or, replacing spaces by newlines: $ echo &quot;Amount of plastic in ocean is worse than we thought, study says&quot; | tr &quot; &quot; &quot;\n&quot; Amount of plastic in ocean is worse than we thought, study says $ Replacing characters can also be done with a sequence of characters as follows: $ echo &quot;Amount of plastic in ocean is worse than we thought, study says&quot; | tr &quot;iplo&quot; &quot;abnu&quot; Amuunt uf bnastac an ucean as wurse than we thuught, study says $ In this case, tr simply translates a character in the first set “iplo” to its corresponding one in the second set “abnu”. tr also supports character sets such as a-z, A-Z and 0-9 to represent lower case alphabets, upper case alphabets and digits, respectively: $ echo &quot;Amount of plastic in ocean is worse than we thought, study says&quot; | tr 'a-z' 'A-Z' AMOUNT OF PLASTIC IN OCEAN IS WORSE THAN WE THOUGHT, STUDY SAYS $ What if we want to replace multiple occurrences of a character by another character? For instance, line 340 to 363 in the sample text file contain multiple spaces that we would like to be removed and be replaced by one. This can be done with the -s option of tr: $ cat noisy_text.txt | awk 'NR &amp;gt;= 340 &amp;amp;&amp;amp; NR &amp;lt;= 350' [3]PART I [4]Item 1. - Business 3 [5]Item 1A. - Risk Factors 23 [6]Item 1B. - Unresolved Staff Comments 37 $ The text looks like the following after removing multiple spaces and newlines: $ cat noisy_text.txt | awk 'NR &amp;gt;= 340 &amp;amp;&amp;amp; NR &amp;lt;= 350' | tr -s &quot; &quot; | tr -s &quot;\n&quot; [3]PART I [4]Item 1. - Business 3 [5]Item 1A. - Risk Factors 23 [6]Item 1B. - Unresolved Staff Comments 37 $ To delete all the occurrences of a character, you can use tr -d [set] which acts like tr [set] &quot;&quot;: $ echo &quot;Amount of plastic in ocean is worse than we thought, study says&quot; | tr -d &quot;o&quot; Amunt f plastic in cean is wrse than we thught, study says $ To discover more interesting options, try man tr. Remove HTML tags (or anything between tags) The commands that we introduced so far were used directly over the text with simple patterns. What if we need to deal with more sophisticated text patterns? This is where regular expressions (regex) come in! Regex allow us to access parts of a text based on the rules that we define. In some ways, a regex is analogous to a database query or a semantic query. It’s a query to extract information from raw text! Let’s take a look at our sample text file where lines 1215 to 1220 contain HTML code (look like an HTML table): $ cat noisy_text.txt | awk 'NR &amp;gt;= 1215 &amp;amp;&amp;amp; NR &amp;lt;= 1220' style=&quot;font-family: Times New Roman;&quot; class=&quot;_mt&quot; &amp;lt;size=&quot;2&quot;&amp;gt;)&amp;amp;nbsp;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td valign=&quot;bottom&quot;&amp;gt;&amp;lt;font class=&quot;_mt&quot; &amp;lt;size=&quot;1&quot;&amp;gt;&amp;amp;nbsp;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td valign=&quot;bottom&quot;&amp;gt;&amp;lt;font style=&quot;font-family: Times New Roman;&quot; class=&quot;_mt&quot; &amp;lt;size=&quot;2&quot;&amp;gt;&amp;amp;nbsp;&amp;lt;/font&amp;gt;&amp;lt;/td&amp;gt; &amp;lt;td valign=&quot;bottom&quot; align=&quot;right&quot;&amp;gt;&amp;lt;font style=&quot;font-family: Times New Roman;&quot; class=&quot;_mt&quot; $ Let’s assume that we want to remove the tags, i.e. anything between &amp;lt; and &amp;gt; and we only want to keep whatever enclosed by tags. To do so, we create a regular expression which looks for anything starting with a &amp;lt; and proceeds until it gets to a &amp;gt;; the regex includes anything between those two characters, except a &amp;gt;. This regex is: /&amp;lt;[^&amp;gt;]*&amp;gt;/. For this problem, we use Perl which is a programming language frequently used in text processing thanks to its facilities. It can also be used in the command-line just like other commands. $ cat noisy_text.txt | awk 'NR &amp;gt;= 1215 &amp;amp;&amp;amp; NR &amp;lt;= 1220' | perl -0777 -pe 's/&amp;lt;[^&amp;gt;]*&amp;gt;//gs' style=&quot;font-family: Times New Roman;&quot; class=&quot;_mt&quot; )&amp;amp;nbsp; &amp;amp;nbsp; &amp;amp;nbsp; &amp;lt;font style=&quot;font-family: Times New Roman;&quot; class=&quot;_mt&quot; $ There are a few details that we should know. -0777 option lets us to slurp the file and feed all the lines to Perl in one go. -pe is composed of two flags: e which allows us to specify the Perl code to be run and, -p flag processes the file line by line. s/[set1]/[set2]/ is the substitution operator which substitutes [set1] by [set2]. /g is the global flag which does the matching over the whole text. /s treats the string as a single long line (only difference is that \n is also included when . is used). Another example with Perl. The following regular expression replaces newlines with more than two occurrences with only two newlines. This can also be done with the previous commands that we introduced, like tr. $ perl -0777 -pe 's/(\n[ ]*){2,}/\n\n/gmi' Here you can learn more about the fascinating functionalities of regular expressions in Perl. Most of the text editors make it easy to test and debug regular expressions and visualizing them. There are also many websites for the same purpose, such as https://regex101.com/. Text split with split Syntax: split [options] filename prefix We perviously mentioned how to merge files using cat. What if we want to split a huge text file into smaller parts? This can be done with split. split allows us to split a file based on the number of lines with -l option and based on size with -b. Let’s split our sample text file into smaller files containing 500 lines each one: $ split -l 500 noisy_text.txt $ tree . ├── noisy_text.txt ├── xaa ├── xab ├── xac └── xad 0 directories, 5 files $ Wrapping up How your text is to be pre-processed depends on the content of your file and your pre-processing purpose. You should know what the noisy stuff are and the issues that should be cleaned or normalised. Suppose that we need the following steps to clean our sample text file: Remove HTML tags (perl -0777 -pe 's/&amp;lt;[^&amp;gt;]*&amp;gt;//gs') Remove noisy non-alphanumeric content (perl -0777 -pe 's/^[\S]*[^\w\s][\S]*$//gmi') Remove unwanted tokens, like javascript:void(0);, and characters (awk '{gsub(/^.*javascript.*$/,&quot;\n&quot;); print }' or awk '{gsub(/&amp;amp;nbsp;/,&quot; &quot;); print }') Following the techniques introduced earlier in this tutorial, we clean the sample text as follows: $ cat noisy_text.txt | awk '{gsub(/^ */,&quot;&quot;); print }' | tr -s &quot; &quot; | perl -0777 -pe 's/^[\S]*[^\w\s][\S]*$//gmi' | perl -0777 -pe 's/&amp;lt;[^&amp;gt;]*&amp;gt;//gs' | awk '{gsub(/^.*javascript.*$/,&quot;\n&quot;); print }' | awk '{gsub(/&amp;amp;nbsp;/,&quot; &quot;); print }' | perl -0777 -pe 's/(\n[ ]*){2,}/\n\n/gmi' &amp;gt; cleaned_noisy_text.txt $ This is how this long command cleans our sample text file like a charm! Last updated on 28 April 2019.</summary></entry><entry><title type="html">RDF Schema reasoning: a tutorial</title><link href="http://localhost:4000/posts/rdf-schema-a-tutorial.html" rel="alternate" type="text/html" title="RDF Schema reasoning: a tutorial" /><published>2019-04-08T00:00:00+01:00</published><updated>2019-04-08T00:00:00+01:00</updated><id>http://localhost:4000/posts/rdf-schema-a-tutorial</id><content type="html" xml:base="http://localhost:4000/posts/rdf-schema-a-tutorial.html">&lt;p&gt;This tutorial is the second part of the &lt;a href=&quot;http://localhost:4000/2019/03/21/rdf-data-modelling-a-tutorial.html&quot; target=&quot;_blank&quot;&gt;Data modelling with RDF: a tutorial&lt;/a&gt;.&lt;/p&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;In the &lt;a href=&quot;http://localhost:4000/2019/03/21/rdf-data-modelling-a-tutorial.html&quot; target=&quot;_blank&quot;&gt;previous tutorial&lt;/a&gt;, we introduced Resource Description Framework (RDF) and how to create a data model using it.&lt;/p&gt;

&lt;!-- RDF is a universal data format which is very useful  --&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 8 April 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="RDF" /><category term="Ontology" /><category term="RDF Schema" /><category term="Linked Data" /><category term="Tutorial" /><summary type="html">This tutorial is the second part of the Data modelling with RDF: a tutorial. In the previous tutorial, we introduced Resource Description Framework (RDF) and how to create a data model using it. Last updated on 8 April 2019.</summary></entry><entry><title type="html">Data modelling with RDF: a tutorial</title><link href="http://localhost:4000/posts/rdf-data-modelling-a-tutorial.html" rel="alternate" type="text/html" title="Data modelling with RDF: a tutorial" /><published>2019-03-21T00:00:00+00:00</published><updated>2019-03-21T00:00:00+00:00</updated><id>http://localhost:4000/posts/rdf-data-modelling-a-tutorial</id><content type="html" xml:base="http://localhost:4000/posts/rdf-data-modelling-a-tutorial.html">&lt;h2 id=&quot;what-is-rdf&quot;&gt;What is RDF?&lt;/h2&gt;

&lt;p&gt;RDF stands for &lt;strong&gt;R&lt;/strong&gt;esource &lt;strong&gt;D&lt;/strong&gt;escription &lt;strong&gt;F&lt;/strong&gt;ramework which is a framework for describing resources on the web. It was initially designed to represent metadata on the Web. However, nowadays RDF is the foundational data model for &lt;a href=&quot;https://www.w3.org/standards/semanticweb/&quot; target=&quot;_blank&quot;&gt;Semantic Web&lt;/a&gt;. In addition, RDF along with other technologies such as SPARQL, OWL, and SKOS empower &lt;a href=&quot;https://www.w3.org/standards/semanticweb/data&quot; target=&quot;_blank&quot;&gt;Linked Data&lt;/a&gt;. In other words, RDF is fun, easier than relational databases and efficient to use.&lt;/p&gt;

&lt;p&gt;RDF expressions are in the form of &lt;code class=&quot;highlighter-rouge&quot;&gt;subject predicate object&lt;/code&gt;, known as triples. Unlike &lt;strong&gt;traditional databases&lt;/strong&gt; where data has to adhere to a fixed schema, there is no prescribed schema for RDF documents. This is the reason that RDF is called &lt;strong&gt;semi-structured&lt;/strong&gt;. On the other hand, an RDF document includes schema information and can be described without additional information. Therefore, RDF data model is self-describing too. The following shows two triples about the capital of France and the population of Paris:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;	(France, capital, Paris)
	(Paris, population, 2141000)&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;However, technically everything has a specific identifier in RDF. The identifier may be URL (Uniform Resource Location), URI (Uniform Resource Identifier (RDF 1.0)) or IRI (Internationalised Resource Identifier (RDF 1.1)). It is also possible to use literals (&lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;) and, blank nodes (&lt;code class=&quot;highlighter-rouge&quot;&gt;B&lt;/code&gt;) when we don’t want to name something. There are restrictions where to use each type of identifiers. The subject can be a URI, URL, IRI or blank node, the predicate is always URL, URI or IRI and the object can be any of the previous mentioned identifiers, i.e. URI, URL, IRI, blank node or literal. So, the correct way of writing the previous example would be the one that respects the restrictions over &lt;code class=&quot;highlighter-rouge&quot;&gt;France&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Paris&lt;/code&gt; as subjects, &lt;code class=&quot;highlighter-rouge&quot;&gt;capital&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;population&lt;/code&gt; as predicates and &lt;code class=&quot;highlighter-rouge&quot;&gt;Paris&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;2141000 &lt;/code&gt; as objects. Although URL, URI and IRI have the same functionality in RDF, we keep mentioning URI in this tutorial for being concise.&lt;/p&gt;

&lt;p&gt;Now, let’s define URI identifiers for &lt;code class=&quot;highlighter-rouge&quot;&gt;France&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Paris&lt;/code&gt;. Don’t you think there were some other people before us who may have attributed an identifier to those famous &lt;em&gt;things&lt;/em&gt;? I say &lt;code class=&quot;highlighter-rouge&quot;&gt;thing&lt;/code&gt;, because once we have not described something, we have no other name to call it but a &lt;code class=&quot;highlighter-rouge&quot;&gt;thing&lt;/code&gt;. Once we identify the nature of that &lt;code class=&quot;highlighter-rouge&quot;&gt;thing&lt;/code&gt;, then we can name it differently. This is how human language works and words are created. Philosophically, such a description is called an &lt;strong&gt;ontology&lt;/strong&gt;. Definitely, there have been some people who thought about an ontology as a &lt;em&gt;Place&lt;/em&gt; and its characteristics. In the same way, &lt;code class=&quot;highlighter-rouge&quot;&gt;Paris&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;France&lt;/code&gt; are defined based on such ontologies and have unique identifiers. The following schema shows a very simple ontology for our scenario where a &lt;code class=&quot;highlighter-rouge&quot;&gt;Place&lt;/code&gt; is defined as a class derived from &lt;code class=&quot;highlighter-rouge&quot;&gt;Thing&lt;/code&gt;, then &lt;code class=&quot;highlighter-rouge&quot;&gt;Country&lt;/code&gt; comes as a sub-class of &lt;code class=&quot;highlighter-rouge&quot;&gt;Place&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;County&lt;/code&gt; as a sub-class of &lt;code class=&quot;highlighter-rouge&quot;&gt;Country&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;City&lt;/code&gt; as a sub-class of &lt;code class=&quot;highlighter-rouge&quot;&gt;County&lt;/code&gt;. The schema also shows our individuals as &lt;code class=&quot;highlighter-rouge&quot;&gt;France&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Ile-de-France&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Paris&lt;/code&gt;.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/place_ontology.png&quot; style=&quot;width:50%&quot; align=&quot;middle&quot; alt=&quot;A simple ontology for Place, including France, Ile-de-France and Paris&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            A simple ontology for Place, including France, Ile-de-France and Paris.
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Now that we know how things are described based on ontologies, we can look on the web to find the identifiers which are attributed to each class and individual. For our example, let’s take a look at &lt;a href=&quot;https://wiki.dbpedia.org/&quot; target=&quot;_blank&quot;&gt;DBpedia&lt;/a&gt;. DBpedia is an amazing platform which provides linked data features for the content of &lt;a href=&quot;https://www.wikipedia.org/&quot; target=&quot;_blank&quot;&gt;Wikipedia&lt;/a&gt;. In other words, it is a tool to semantically query whatever exists on Wikipedia. For instance, &lt;code class=&quot;highlighter-rouge&quot;&gt;http://dbpedia.org/resource/France&lt;/code&gt; and  &lt;code class=&quot;highlighter-rouge&quot;&gt;http://dbpedia.org/resource/Paris&lt;/code&gt; are the identifiers for &lt;a href=&quot;http://dbpedia.org/resource/France&quot; target=&quot;_blank&quot;&gt;France&lt;/a&gt; and &lt;a href=&quot;http://dbpedia.org/resource/Paris&quot; target=&quot;_blank&quot;&gt;Paris&lt;/a&gt; respectively. You get something like the following for Paris as the capital of France:&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/paris_dbpedia.png&quot; style=&quot;width:100%&quot; align=&quot;middle&quot; alt=&quot;Paris as the capital of France in DBpedia&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Paris as the capital of France in DBpedia.
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;rdf-in-practice&quot;&gt;RDF in practice&lt;/h3&gt;

&lt;p&gt;There are various ways to represent RDF data, namely &lt;a href=&quot;https://www.w3.org/TR/2004/NOTE-owl-parsing-20040121/&quot; target=&quot;_blank&quot;&gt;RDF/XML&lt;/a&gt;, &lt;a href=&quot;https://www.w3.org/TR/rdfa-lite/&quot; target=&quot;_blank&quot;&gt;RDFa&lt;/a&gt;, &lt;a href=&quot;https://www.w3.org/TR/2018/WD-json-ld11-20181214/&quot; target=&quot;_blank&quot;&gt;JSON-LD&lt;/a&gt;, &lt;a href=&quot;https://www.w3.org/TR/n-triples/&quot; target=&quot;_blank&quot;&gt;N-Triples&lt;/a&gt; and &lt;a href=&quot;https://www.w3.org/TR/turtle/&quot; target=&quot;_blank&quot;&gt;Turtle&lt;/a&gt;, among which we will focus on the two latter ones in this tutorial.&lt;/p&gt;

&lt;h4 id=&quot;n-triples&quot;&gt;N-Triples&lt;/h4&gt;

&lt;p&gt;N-Triples is a line-based and a concrete syntax for RDF. N-Triples are a sequence of RDF terms in the form of &lt;code class=&quot;highlighter-rouge&quot;&gt;subject predicate object&lt;/code&gt;, separated by white space and terminated by a ‘.’. The following shows the aforementioned example in N-Triples:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;&amp;lt;http://dbpedia.org/resource/France&amp;gt; &amp;lt;http://dbpedia.org/ontology/capital&amp;gt; &amp;lt;http://dbpedia.org/resource/Paris&amp;gt; .
&amp;lt;http://dbpedia.org/resource/Paris&amp;gt; &amp;lt;http://dbpedia.org/ontology/populationTotal&amp;gt; &quot;2229621&quot;^^xsd:integer .&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;As you see, we used URI for all the subjects, predicates and objects, but for the population which is a literal. In this case, we determined the type of the literal as an integer using &lt;code class=&quot;highlighter-rouge&quot;&gt;xsd:integer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The followings are a few other data types in XSD which are also supported in RDF:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;xsd:boolean&lt;/li&gt;
  &lt;li&gt;xsd:byte&lt;/li&gt;
  &lt;li&gt;xsd:date&lt;/li&gt;
  &lt;li&gt;xsd:decimal&lt;/li&gt;
  &lt;li&gt;xsd:double&lt;/li&gt;
  &lt;li&gt;xsd:integer&lt;/li&gt;
  &lt;li&gt;xsd:string&lt;/li&gt;
  &lt;li&gt;xsd:language&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that the default value of literals is &lt;code class=&quot;highlighter-rouge&quot;&gt;String&lt;/code&gt;.&lt;/p&gt;

&lt;h4 id=&quot;turtle&quot;&gt;Turtle&lt;/h4&gt;

&lt;p&gt;An easier way for representing RDF data is Turtle. Turtle is a more convenient version of N-Triples where we can:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;define prefixes so that we use shorter triples.&lt;/li&gt;
  &lt;li&gt;avoid repeating subjects by using ‘;’ between two triples.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following shows our examples in Turtle:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;@prefix dbr: &amp;lt;http://dbpedia.org/resource/&amp;gt;
@prefix dbo: &amp;lt;http://dbpedia.org/ontology/&amp;gt;

dbr:France dbo:capital dbr:Paris .
dbr:Paris dbo:populationTotal &quot;2229621&quot;^^xsd:integer .&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;data-modelling&quot;&gt;Data modelling&lt;/h2&gt;

&lt;p&gt;Hopefully, you are now familiar with the basics of RDF and how to represent them. In this section, we would like to create a data model. All you need to know is the following 4 principals which form what is known as RDF Schema (&lt;a href=&quot;https://www.w3.org/TR/rdf-schema/&quot; target=&quot;_blank&quot;&gt;RDFS&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Class hierarchy&lt;/strong&gt;: a class can be a sub-class of a parent class. For instance, &lt;code class=&quot;highlighter-rouge&quot;&gt;Bird&lt;/code&gt; can be defined as a class which is the sub-class of the class &lt;code class=&quot;highlighter-rouge&quot;&gt;Animal&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Property hierarchy&lt;/strong&gt;: a property can be a sub-property of another property. Think of a property called &lt;code class=&quot;highlighter-rouge&quot;&gt;Moves&lt;/code&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;MoviesByCar&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;MovesByTrain&lt;/code&gt; can be  defined as the sub-properties of &lt;code class=&quot;highlighter-rouge&quot;&gt;Moves&lt;/code&gt; as they are the same functionality with a specificity.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Domain&lt;/strong&gt; and &lt;strong&gt;Range&lt;/strong&gt; of properties: Think of a &lt;code class=&quot;highlighter-rouge&quot;&gt;property&lt;/code&gt; as a function. A function has a domain and a range. The domain is what the function (or here the property) gets as input, and the range is what the function (or here the property) produces an output.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-student-management-system-data-model&quot;&gt;Example: Student management system data model&lt;/h3&gt;

&lt;p&gt;Consider a scenario of designing a linked data application for a university student management system. Design a data model (ontology) to represent the information related to the students, study programs, modules and students’ grades in the exams.&lt;/p&gt;

&lt;h4 id=&quot;step-1-identify-the-components-of-your-ontology&quot;&gt;Step 1: Identify the components of your ontology&lt;/h4&gt;

&lt;p&gt;A strategy to identify classes, sub-classes, properties and sub-properties is to initially describe your ontology in plain English. Something like the following:&lt;/p&gt;

&lt;div class=&quot;ml-3&quot;&gt;
&lt;p class=&quot;text-muted&quot;&gt;
- A student management system helps to organise information about Students.
- Each Student is a Person.
- A programme is a class that the Student enrols in. Each programme is composed of various modules.
- There are different levels of degree.
- There are a hierarchy of classes belonging to Place.
- A Student can take an Exam.
- A University has various Faculties.
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Now, it is easier to detect classes and properties as the following:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Classes and sub-classes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Person
    &lt;ul&gt;
      &lt;li&gt;Student&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Programme
    &lt;ul&gt;
      &lt;li&gt;Module&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Degree
    &lt;ul&gt;
      &lt;li&gt;B.Sc.&lt;/li&gt;
      &lt;li&gt;M.Sc.&lt;/li&gt;
      &lt;li&gt;Ph.D.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Place
    &lt;ul&gt;
      &lt;li&gt;Country
        &lt;ul&gt;
          &lt;li&gt;County
            &lt;ul&gt;
              &lt;li&gt;City&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;University
    &lt;ul&gt;
      &lt;li&gt;Faculty&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Exam&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Properties and sub-properties&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;AttendsIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;EnrolledIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasStudentID&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasModuleID&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasProgrammeID&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;TakesExam&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;RegisteredIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasDegree&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasName&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;livesIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;wasBornIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;wasBornOn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;isLocatedIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;takesPlaceIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasEnrollementDate&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;startedStudyingIn&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasGrade&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasModuleID&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasProgrammeID&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasUniName&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasModuleName&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;hasProgrammeName&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;isPartOf&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;“hasDate” could be a sub-property of “EnrolledIn”, “Attends”, “TakesExam” and “RegisteredIn”. However, in the current data model I have not used any sub-property.&lt;/p&gt;

&lt;h4 id=&quot;step-2-draw-a-graphical-representation-of-your-information-model&quot;&gt;Step 2: Draw a graphical representation of your information model.&lt;/h4&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/webnetwork_1.jpeg&quot; style=&quot;width:100%&quot; align=&quot;middle&quot; alt=&quot;Student management system data model schema&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Schema of a data model for student management system (&lt;i&gt;classes&lt;/i&gt; are highlighted in yellow and &lt;i&gt;properties&lt;/i&gt; in green).
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Your ontology is not exactly identical with this one? Well, this is normal as more than one way may exist to create an ontology with the same functionality. So, yours may also be a valid ontology but different from the above one.&lt;/p&gt;

&lt;h4 id=&quot;step-3-model-the-above-information-into-rdf-data-model&quot;&gt;Step 3: Model the above information into RDF data model&lt;/h4&gt;

&lt;p&gt;Let’s represent our ontology in RDF now. We will try N-Triples and Turtle formats. Usually to save time not to look for the identifiers of the classes on the web, “http://www.example.org” is used to define a URI. For instance, we can create &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;http://www.example.org/hasName&amp;gt;&lt;/code&gt; as the URI of &lt;code class=&quot;highlighter-rouge&quot;&gt;hasName&lt;/code&gt; property.&lt;/p&gt;

&lt;h5 id=&quot;n-triples-1&quot;&gt;N-Triples&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;&amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/hasName&amp;gt;    “Person name” .
&amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/LivesIn&amp;gt;     &amp;lt;http://www.example.org/Place&amp;gt;  .
&amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/WasBornIn&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt;  .

&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/EnrolledIn&amp;gt;    &amp;lt;http://www.example.org/Programme&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt;    &amp;lt;http://www.example.org/Module&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/TakesExam&amp;gt;    &amp;lt;http://www.example.org/Exam&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/RegisteredIn&amp;gt;    &amp;lt;http://www.example.org/University&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/hasDegree&amp;gt;    &amp;lt;http://www.example.org/Degree&amp;gt;  .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/hasStudentID&amp;gt;  “Student ID” .
&amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/StartedStudyingOn&amp;gt; “Starting Date” .

&amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/hasProgrammeName&amp;gt;    “Programme Name” .
&amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/hasProgrammeID&amp;gt;    “Programme ID” .
&amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/isPartOf&amp;gt;    &amp;lt;http://www.example.org/University/Faculty&amp;gt;  .

&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Programme&amp;gt; .
&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “Module ID” .
&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasNameID&amp;gt; “Module Name” .
&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt; “Grade” .
&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasEnrollmentDate&amp;gt; “Enrollment Date” .
&amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/takesPlaceIn&amp;gt;    &amp;lt;http://www.example.org/University/Faculty&amp;gt;  .

&amp;lt;http://www.example.org/Exam&amp;gt; &amp;lt;http://www.example.org/hasNameExam&amp;gt; “Exam Name” .

&amp;lt;http://www.example.org/University&amp;gt; &amp;lt;http://www.example.org/hasUniversityName&amp;gt; “University Name” .
&amp;lt;http://www.example.org/University&amp;gt; &amp;lt;http://www.example.org/isLocatedIn&amp;gt; Place .

&amp;lt;http://www.example.org/University/Faculty&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;  &amp;lt;http://www.example.org/University&amp;gt;  .

&amp;lt;http://www.example.org/Degree/BSc&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;     &amp;lt;http://www.example.org/Degree&amp;gt;  .
&amp;lt;http://www.example.org/Degree/MSc&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;     &amp;lt;http://www.example.org/Degree&amp;gt;  .
&amp;lt;http://www.example.org/Degree/PhD&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;  &amp;lt;http://www.example.org/Degree&amp;gt;  .

&amp;lt;http://www.example.org/Place/Country&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; .
&amp;lt;http://www.example.org/Place/County&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; .
&amp;lt;http://www.example.org/Place/City&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; .&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h5 id=&quot;turtle-1&quot;&gt;Turtle&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;@prefix    foaf:     &amp;lt;http://xmlns.com/foaf/0.1/&amp;gt; .
@prefix    prop:    &amp;lt;http://www.example.org/ .
@prefix    stu:    &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; .
@prefix    subclass    &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; .
@prefix    prog    &amp;lt;http://www.example.org/Programme&amp;gt; .
@prefix    univ    &amp;lt;http://www.example.org/University&amp;gt; .
@prefix    deg    &amp;lt;http://www.example.org/Degree&amp;gt; .
@prefix    place    &amp;lt;http://www.example.org/Place&amp;gt; .

foaf prop:hasName    “Person name” .
foaf prop:LivesIn     place: .
foaf prop:WasBornIn place: .

stu subclass foaf .
stu prop:EnrolledIn    prop:Programme .
stu prop:AttendsIn    prop:Module .
stu prop:TakesExam    prop:Exam .
stu prop:RegisteredIn    univ .
stu prop:hasDegree    deg  .
stu prop:hasStudentID  “Student ID” .
stu prop:StartedStudyingOn “Starting Date” .

prog prop:hasProgrammeName    “Programme Name” .
prog prop:hasProgrammeID    “Programme ID” .
prog prop:isPartOf    uni:Faculty  .

prog:Module subclass prog .
prog:Module prop:hasModuleID “Module ID” .
prog:Module prop:hasNameID “Module Name” .
prog:Module prop:hasGrade “Grade” .
prog:Module prop:hasEnrollmentDate    “Enrollment Date” .
prog:Module prop:takesPlaceIn    univ:Faculty  .

prop:Exam prop:hasNameExam “Exam Name” .

univ: prop:hasUniversityName “University Name” .
univ: prop:isLocatedIn Place .

uni:Faculty subclass:  univ  .

deg:BSc subclass  deg:  .
deg:MSc subclass  deg:  .
deg:PhD subclass  deg: .

place:Country subclass place:Place .
place:County subclass place:Place .
place:City subclass place:Place .&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;extract-rdf-triples&quot;&gt;Extract RDF triples&lt;/h4&gt;

&lt;p&gt;What we have been doing so far was defining the ontology. Our student management ontology, like a data template, can be used to describe Bob, David and all students.&lt;/p&gt;

&lt;p&gt;Given the following description of a student:&lt;/p&gt;

&lt;div class=&quot;ml-3&quot;&gt;
&lt;p class=&quot;text-muted&quot;&gt;
David is a student at NUI Galway. He is enrolled in M.Sc. Data Analytics program. David was born on February 20th, 1988 in County Mayo, Ireland. He now lives in Galway. He started his studies at NUI Galway in September 2018. He was enrolled in the following modules: L19872 (Linked Data), IT822 (Programming Languages) and MTH700 (Calculus) during first semester of the academic year 2018-19. The semester started on Monday 15th September. All exams were conducted on Friday 14th December 2018. David got A-, B+ and D grades in L19872, IT822 and MTH700.&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Let’s rewrite the description based on our ontology.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-plaintext&quot; data-lang=&quot;plaintext&quot;&gt;&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;    &amp;lt;http://xmlns.com/foaf/0.1/Person/&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;     &amp;lt;http://www.example.org/hasName&amp;gt;    “David” .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.example.org/RegisteredIn&amp;gt;    “NUIG” .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.example.org/EnrolledIn&amp;gt;    “Data Analytics” .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.example.org/hasDegree&amp;gt;    &amp;lt;http://www.example.org/Degree/MSc&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.example.org/WasBornIn&amp;gt;    &amp;lt;http://www.example.org/Place/CountyMayo&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt;    &amp;lt;http://www.example.org/WasBornOn&amp;gt;    “20/02/1988”^^xsd:date     .
&amp;lt;http://www.example.org/Place/CountyMayo&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt;    &amp;lt;http://www.example.org/Place/Ireland&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/livesIn&amp;gt; &amp;lt;http://www.example.org/Place/Galway&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/startedStudyingOn&amp;gt;    “September 2018”^^xsd:date .

&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; .
&amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; .

&amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Linked Data”     .
&amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “L19872” .
&amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt;    “Semester 1 2018/19”^^xsd:date .
&amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Programming Languages”     .
&amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “IT822” .
&amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt;    “Semester 1 2018/19”^^xsd:date .
&amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Calculus”     .
&amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “MTH700” .
&amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt;    “Semester 1 2018/19”^^xsd:date .

&amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt;    “A-” .
&amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt;    “B+” .
&amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt;    “D” .

&amp;lt;http://www.example.org/Programme/Semester&amp;gt; &amp;lt;http://www.example.org/hasDate&amp;gt;    “Monday Sep 15,  2018”^^xsd:date .
&amp;lt;http://www.example.org/Programme/Exam&amp;gt;     &amp;lt;http://www.example.org/hasDate&amp;gt;    “December 14,  2018”^^xsd:date .&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 28 March 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="RDF" /><category term="Ontology" /><category term="Data model" /><category term="Linked Data" /><category term="Tutorial" /><summary type="html">What is RDF? RDF stands for Resource Description Framework which is a framework for describing resources on the web. It was initially designed to represent metadata on the Web. However, nowadays RDF is the foundational data model for Semantic Web. In addition, RDF along with other technologies such as SPARQL, OWL, and SKOS empower Linked Data. In other words, RDF is fun, easier than relational databases and efficient to use. RDF expressions are in the form of subject predicate object, known as triples. Unlike traditional databases where data has to adhere to a fixed schema, there is no prescribed schema for RDF documents. This is the reason that RDF is called semi-structured. On the other hand, an RDF document includes schema information and can be described without additional information. Therefore, RDF data model is self-describing too. The following shows two triples about the capital of France and the population of Paris: (France, capital, Paris) (Paris, population, 2141000) However, technically everything has a specific identifier in RDF. The identifier may be URL (Uniform Resource Location), URI (Uniform Resource Identifier (RDF 1.0)) or IRI (Internationalised Resource Identifier (RDF 1.1)). It is also possible to use literals (L) and, blank nodes (B) when we don’t want to name something. There are restrictions where to use each type of identifiers. The subject can be a URI, URL, IRI or blank node, the predicate is always URL, URI or IRI and the object can be any of the previous mentioned identifiers, i.e. URI, URL, IRI, blank node or literal. So, the correct way of writing the previous example would be the one that respects the restrictions over France and Paris as subjects, capital and population as predicates and Paris and 2141000 as objects. Although URL, URI and IRI have the same functionality in RDF, we keep mentioning URI in this tutorial for being concise. Now, let’s define URI identifiers for France and Paris. Don’t you think there were some other people before us who may have attributed an identifier to those famous things? I say thing, because once we have not described something, we have no other name to call it but a thing. Once we identify the nature of that thing, then we can name it differently. This is how human language works and words are created. Philosophically, such a description is called an ontology. Definitely, there have been some people who thought about an ontology as a Place and its characteristics. In the same way, Paris and France are defined based on such ontologies and have unique identifiers. The following schema shows a very simple ontology for our scenario where a Place is defined as a class derived from Thing, then Country comes as a sub-class of Place, County as a sub-class of Country and City as a sub-class of County. The schema also shows our individuals as France, Ile-de-France and Paris. A simple ontology for Place, including France, Ile-de-France and Paris. Now that we know how things are described based on ontologies, we can look on the web to find the identifiers which are attributed to each class and individual. For our example, let’s take a look at DBpedia. DBpedia is an amazing platform which provides linked data features for the content of Wikipedia. In other words, it is a tool to semantically query whatever exists on Wikipedia. For instance, http://dbpedia.org/resource/France and http://dbpedia.org/resource/Paris are the identifiers for France and Paris respectively. You get something like the following for Paris as the capital of France: Paris as the capital of France in DBpedia. RDF in practice There are various ways to represent RDF data, namely RDF/XML, RDFa, JSON-LD, N-Triples and Turtle, among which we will focus on the two latter ones in this tutorial. N-Triples N-Triples is a line-based and a concrete syntax for RDF. N-Triples are a sequence of RDF terms in the form of subject predicate object, separated by white space and terminated by a ‘.’. The following shows the aforementioned example in N-Triples: &amp;lt;http://dbpedia.org/resource/France&amp;gt; &amp;lt;http://dbpedia.org/ontology/capital&amp;gt; &amp;lt;http://dbpedia.org/resource/Paris&amp;gt; . &amp;lt;http://dbpedia.org/resource/Paris&amp;gt; &amp;lt;http://dbpedia.org/ontology/populationTotal&amp;gt; &quot;2229621&quot;^^xsd:integer . As you see, we used URI for all the subjects, predicates and objects, but for the population which is a literal. In this case, we determined the type of the literal as an integer using xsd:integer. The followings are a few other data types in XSD which are also supported in RDF: xsd:boolean xsd:byte xsd:date xsd:decimal xsd:double xsd:integer xsd:string xsd:language Note that the default value of literals is String. Turtle An easier way for representing RDF data is Turtle. Turtle is a more convenient version of N-Triples where we can: define prefixes so that we use shorter triples. avoid repeating subjects by using ‘;’ between two triples. The following shows our examples in Turtle: @prefix dbr: &amp;lt;http://dbpedia.org/resource/&amp;gt; @prefix dbo: &amp;lt;http://dbpedia.org/ontology/&amp;gt; dbr:France dbo:capital dbr:Paris . dbr:Paris dbo:populationTotal &quot;2229621&quot;^^xsd:integer . Data modelling Hopefully, you are now familiar with the basics of RDF and how to represent them. In this section, we would like to create a data model. All you need to know is the following 4 principals which form what is known as RDF Schema (RDFS): Class hierarchy: a class can be a sub-class of a parent class. For instance, Bird can be defined as a class which is the sub-class of the class Animal. Property hierarchy: a property can be a sub-property of another property. Think of a property called Moves. MoviesByCar and MovesByTrain can be defined as the sub-properties of Moves as they are the same functionality with a specificity. Domain and Range of properties: Think of a property as a function. A function has a domain and a range. The domain is what the function (or here the property) gets as input, and the range is what the function (or here the property) produces an output. Example: Student management system data model Consider a scenario of designing a linked data application for a university student management system. Design a data model (ontology) to represent the information related to the students, study programs, modules and students’ grades in the exams. Step 1: Identify the components of your ontology A strategy to identify classes, sub-classes, properties and sub-properties is to initially describe your ontology in plain English. Something like the following: - A student management system helps to organise information about Students. - Each Student is a Person. - A programme is a class that the Student enrols in. Each programme is composed of various modules. - There are different levels of degree. - There are a hierarchy of classes belonging to Place. - A Student can take an Exam. - A University has various Faculties. Now, it is easier to detect classes and properties as the following: Classes and sub-classes Person Student Programme Module Degree B.Sc. M.Sc. Ph.D. Place Country County City University Faculty Exam Properties and sub-properties AttendsIn EnrolledIn hasStudentID hasModuleID hasProgrammeID TakesExam RegisteredIn hasDegree hasName livesIn wasBornIn wasBornOn isLocatedIn takesPlaceIn hasEnrollementDate startedStudyingIn hasGrade hasModuleID hasProgrammeID hasUniName hasModuleName hasProgrammeName isPartOf “hasDate” could be a sub-property of “EnrolledIn”, “Attends”, “TakesExam” and “RegisteredIn”. However, in the current data model I have not used any sub-property. Step 2: Draw a graphical representation of your information model. Schema of a data model for student management system (classes are highlighted in yellow and properties in green). Your ontology is not exactly identical with this one? Well, this is normal as more than one way may exist to create an ontology with the same functionality. So, yours may also be a valid ontology but different from the above one. Step 3: Model the above information into RDF data model Let’s represent our ontology in RDF now. We will try N-Triples and Turtle formats. Usually to save time not to look for the identifiers of the classes on the web, “http://www.example.org” is used to define a URI. For instance, we can create &amp;lt;http://www.example.org/hasName&amp;gt; as the URI of hasName property. N-Triples &amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/hasName&amp;gt; “Person name” . &amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/LivesIn&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; &amp;lt;http://www.example.org/WasBornIn&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://xmlns.com/foaf/0.1/Person&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/EnrolledIn&amp;gt; &amp;lt;http://www.example.org/Programme&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Module&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/TakesExam&amp;gt; &amp;lt;http://www.example.org/Exam&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/RegisteredIn&amp;gt; &amp;lt;http://www.example.org/University&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/hasDegree&amp;gt; &amp;lt;http://www.example.org/Degree&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/hasStudentID&amp;gt; “Student ID” . &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; &amp;lt;http://www.example.org/StartedStudyingOn&amp;gt; “Starting Date” . &amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/hasProgrammeName&amp;gt; “Programme Name” . &amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/hasProgrammeID&amp;gt; “Programme ID” . &amp;lt;http://www.example.org/Programme&amp;gt; &amp;lt;http://www.example.org/isPartOf&amp;gt; &amp;lt;http://www.example.org/University/Faculty&amp;gt; . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Programme&amp;gt; . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “Module ID” . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasNameID&amp;gt; “Module Name” . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt; “Grade” . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/hasEnrollmentDate&amp;gt; “Enrollment Date” . &amp;lt;http://www.example.org/Programme/Module&amp;gt; &amp;lt;http://www.example.org/takesPlaceIn&amp;gt; &amp;lt;http://www.example.org/University/Faculty&amp;gt; . &amp;lt;http://www.example.org/Exam&amp;gt; &amp;lt;http://www.example.org/hasNameExam&amp;gt; “Exam Name” . &amp;lt;http://www.example.org/University&amp;gt; &amp;lt;http://www.example.org/hasUniversityName&amp;gt; “University Name” . &amp;lt;http://www.example.org/University&amp;gt; &amp;lt;http://www.example.org/isLocatedIn&amp;gt; Place . &amp;lt;http://www.example.org/University/Faculty&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/University&amp;gt; . &amp;lt;http://www.example.org/Degree/BSc&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Degree&amp;gt; . &amp;lt;http://www.example.org/Degree/MSc&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Degree&amp;gt; . &amp;lt;http://www.example.org/Degree/PhD&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Degree&amp;gt; . &amp;lt;http://www.example.org/Place/Country&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; . &amp;lt;http://www.example.org/Place/County&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; . &amp;lt;http://www.example.org/Place/City&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place&amp;gt; . Turtle @prefix foaf: &amp;lt;http://xmlns.com/foaf/0.1/&amp;gt; . @prefix prop: &amp;lt;http://www.example.org/ . @prefix stu: &amp;lt;http://xmlns.com/foaf/0.1/Person/Student&amp;gt; . @prefix subclass &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; . @prefix prog &amp;lt;http://www.example.org/Programme&amp;gt; . @prefix univ &amp;lt;http://www.example.org/University&amp;gt; . @prefix deg &amp;lt;http://www.example.org/Degree&amp;gt; . @prefix place &amp;lt;http://www.example.org/Place&amp;gt; . foaf prop:hasName “Person name” . foaf prop:LivesIn place: . foaf prop:WasBornIn place: . stu subclass foaf . stu prop:EnrolledIn prop:Programme . stu prop:AttendsIn prop:Module . stu prop:TakesExam prop:Exam . stu prop:RegisteredIn univ . stu prop:hasDegree deg . stu prop:hasStudentID “Student ID” . stu prop:StartedStudyingOn “Starting Date” . prog prop:hasProgrammeName “Programme Name” . prog prop:hasProgrammeID “Programme ID” . prog prop:isPartOf uni:Faculty . prog:Module subclass prog . prog:Module prop:hasModuleID “Module ID” . prog:Module prop:hasNameID “Module Name” . prog:Module prop:hasGrade “Grade” . prog:Module prop:hasEnrollmentDate “Enrollment Date” . prog:Module prop:takesPlaceIn univ:Faculty . prop:Exam prop:hasNameExam “Exam Name” . univ: prop:hasUniversityName “University Name” . univ: prop:isLocatedIn Place . uni:Faculty subclass: univ . deg:BSc subclass deg: . deg:MSc subclass deg: . deg:PhD subclass deg: . place:Country subclass place:Place . place:County subclass place:Place . place:City subclass place:Place . Extract RDF triples What we have been doing so far was defining the ontology. Our student management ontology, like a data template, can be used to describe Bob, David and all students. Given the following description of a student: David is a student at NUI Galway. He is enrolled in M.Sc. Data Analytics program. David was born on February 20th, 1988 in County Mayo, Ireland. He now lives in Galway. He started his studies at NUI Galway in September 2018. He was enrolled in the following modules: L19872 (Linked Data), IT822 (Programming Languages) and MTH700 (Calculus) during first semester of the academic year 2018-19. The semester started on Monday 15th September. All exams were conducted on Friday 14th December 2018. David got A-, B+ and D grades in L19872, IT822 and MTH700. Let’s rewrite the description based on our ontology. &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://xmlns.com/foaf/0.1/Person/&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/hasName&amp;gt; “David” . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/RegisteredIn&amp;gt; “NUIG” . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/EnrolledIn&amp;gt; “Data Analytics” . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/hasDegree&amp;gt; &amp;lt;http://www.example.org/Degree/MSc&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/WasBornIn&amp;gt; &amp;lt;http://www.example.org/Place/CountyMayo&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/WasBornOn&amp;gt; “20/02/1988”^^xsd:date . &amp;lt;http://www.example.org/Place/CountyMayo&amp;gt; &amp;lt;http://www.w3.org/2000/01/rdf-schema#SubClass&amp;gt; &amp;lt;http://www.example.org/Place/Ireland&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/livesIn&amp;gt; &amp;lt;http://www.example.org/Place/Galway&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/startedStudyingOn&amp;gt; “September 2018”^^xsd:date . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; . &amp;lt;http://xmlns.com/foaf/0.1/Student/David&amp;gt; &amp;lt;http://www.example.org/AttendsIn&amp;gt; &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; . &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Linked Data” . &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “L19872” . &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt; “Semester 1 2018/19”^^xsd:date . &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Programming Languages” . &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “IT822” . &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt; “Semester 1 2018/19”^^xsd:date . &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasModuleName&amp;gt; “Calculus” . &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasModuleID&amp;gt; “MTH700” . &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasEnrolDate&amp;gt; “Semester 1 2018/19”^^xsd:date . &amp;lt;http://www.example.org/Programme/Module/1&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt; “A-” . &amp;lt;http://www.example.org/Programme/Module/2&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt; “B+” . &amp;lt;http://www.example.org/Programme/Module/3&amp;gt; &amp;lt;http://www.example.org/hasGrade&amp;gt; “D” . &amp;lt;http://www.example.org/Programme/Semester&amp;gt; &amp;lt;http://www.example.org/hasDate&amp;gt; “Monday Sep 15, 2018”^^xsd:date . &amp;lt;http://www.example.org/Programme/Exam&amp;gt; &amp;lt;http://www.example.org/hasDate&amp;gt; “December 14, 2018”^^xsd:date . Last updated on 28 March 2019.</summary></entry><entry><title type="html">Foreign loanwords in Modern Greek</title><link href="http://localhost:4000/posts/foreign-loanwords-in-modern-greek.html" rel="alternate" type="text/html" title="Foreign loanwords in Modern Greek" /><published>2019-03-18T00:00:00+00:00</published><updated>2019-03-18T00:00:00+00:00</updated><id>http://localhost:4000/posts/foreign-loanwords-in-modern-greek</id><content type="html" xml:base="http://localhost:4000/posts/foreign-loanwords-in-modern-greek.html">&lt;p&gt;It is not exaggeration to say that Greek is the mother language of knowledge. No other civilisation other than Hellenism played such a primordial role in seeking for knowledge and enriching human’s understanding of the world and the nature. No doubt, there were other civilisations with wonderful achievements and contributions to humanity, but none of them seems to have preserved their works as good as Greeks did by writing. Mathematics, physics, medicine, literature, philosophy are some of the branches of knowledge that Greeks contributed to by using their language to name their findings. Imagine Plato describing for the first time his ideas about the dialectical forms of government in &lt;a href=&quot;https://en.wikipedia.org/wiki/Republic_(Plato){:target=&amp;quot;_blank&amp;quot;}&quot;&gt;the Republic&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/owl_greek.jpeg&quot; style=&quot;width:50%&quot; align=&quot;middle&quot; alt=&quot;Greek words in English&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Some of the Greek words in English
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;So, no surprise that there are still thousands of Greek words in European languages. According to &lt;a href=&quot;https://books.google.ie/books?id=GA0WBAAAQBAJ&amp;amp;lpg=PR5&amp;amp;ots=jWJ623QSra&amp;amp;dq=number%20of%20greek%20words%20in%20english&amp;amp;lr&amp;amp;pg=PP1#v=onepage&amp;amp;q=number%20of%20greek%20words%20in%20english&amp;amp;f=false&quot; target=&quot;_blank&quot;&gt;The Greek &amp;amp; Latin Roots of English&lt;/a&gt;, around 60% of all English words have Greek or Latin roots. But what about foreign loanwords in Modern Greek?&lt;/p&gt;

&lt;p&gt;Καρακάξα, νόμπιλος, κέφι, ρεζερβουάρ, παρασόλι… If you have studied Greek language, I am sure you also feel that those words do not seem to be of Greek origin. Whenever I come across such Greek words, I get curious of the number of foreign words in Modern Greek. Happily, I could find a book that addresses this topic: &lt;a href=&quot;https://www.politeianet.gr/books/9789602050859-konstantinou-i-ilias-epikairotita-lexiko-ton-xenon-lexeon-stin-elliniki-glossa-143806&quot; target=&quot;_blank&quot;&gt;Λεξικό των ξένων λέξεων στην ελληνική γλώσσα&lt;/a&gt; by Ηλίας Κωνσταντίνου describes the words which are originally from foreign languages and used in the Greek language. As I could not find a similar study available online, I created the following donut chart based on the statistics of this resource to show the distribution of the whole &lt;strong&gt;4037&lt;/strong&gt; foreign loanwords in modern Greek.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
&lt;iframe width=&quot;700&quot; height=&quot;500&quot; align=&quot;middle&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plot.ly/~sinahm/14.embed?showlink=false&quot;&gt;&lt;/iframe&gt;
&lt;div class=&quot;card-body bg-light&quot;&gt;
    &lt;div class=&quot;card-text&quot;&gt;
      Foreign loanwords in Modern Greek. Data from
        &lt;a href=&quot;https://www.politeianet.gr/books/9789602050859-konstantinou-i-ilias-epikairotita-lexiko-ton-xenon-lexeon-stin-elliniki-glossa-143806&quot; target=&quot;_blank&quot;&gt;Λεξικό των ξένων λέξεων στην ελληνική γλώσσα&lt;/a&gt;.
    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Curious which Greek words are from foreign origin? Visit the following links:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ellinopedia.com/ellinika/italikes-lexis-stin-elliniki-glossa&quot; target=&quot;_blank&quot;&gt;Italian words in Greek&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ellinopedia.com/ellinika/tourkikes-lexis-stin-elliniki-glossa&quot; target=&quot;_blank&quot;&gt;Turkish words in Greek&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ellinopedia.com/ellinika/gallikes-lexis-pou-xrisimopioume-stin-ellada&quot; target=&quot;_blank&quot;&gt;French words in Greek&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ellinopedia.com/germanika/germanikes-lexeis-stin-elliniki-glossa&quot; target=&quot;_blank&quot;&gt;German words in Greek&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ellinopedia.com/anglika/anglikes-lexis-stin-elliniki&quot; target=&quot;_blank&quot;&gt;English words in Greek&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 20 March 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="Modern Greek" /><summary type="html">It is not exaggeration to say that Greek is the mother language of knowledge. No other civilisation other than Hellenism played such a primordial role in seeking for knowledge and enriching human’s understanding of the world and the nature. No doubt, there were other civilisations with wonderful achievements and contributions to humanity, but none of them seems to have preserved their works as good as Greeks did by writing. Mathematics, physics, medicine, literature, philosophy are some of the branches of knowledge that Greeks contributed to by using their language to name their findings. Imagine Plato describing for the first time his ideas about the dialectical forms of government in the Republic. Some of the Greek words in English So, no surprise that there are still thousands of Greek words in European languages. According to The Greek &amp;amp; Latin Roots of English, around 60% of all English words have Greek or Latin roots. But what about foreign loanwords in Modern Greek? Καρακάξα, νόμπιλος, κέφι, ρεζερβουάρ, παρασόλι… If you have studied Greek language, I am sure you also feel that those words do not seem to be of Greek origin. Whenever I come across such Greek words, I get curious of the number of foreign words in Modern Greek. Happily, I could find a book that addresses this topic: Λεξικό των ξένων λέξεων στην ελληνική γλώσσα by Ηλίας Κωνσταντίνου describes the words which are originally from foreign languages and used in the Greek language. As I could not find a similar study available online, I created the following donut chart based on the statistics of this resource to show the distribution of the whole 4037 foreign loanwords in modern Greek. Foreign loanwords in Modern Greek. Data from Λεξικό των ξένων λέξεων στην ελληνική γλώσσα. Curious which Greek words are from foreign origin? Visit the following links: Italian words in Greek Turkish words in Greek French words in Greek German words in Greek English words in Greek Last updated on 20 March 2019.</summary></entry><entry><title type="html">Why does Kurdish language processing matter?</title><link href="http://localhost:4000/posts/why-kurdish-language-processing-matters.html" rel="alternate" type="text/html" title="Why does Kurdish language processing matter?" /><published>2019-03-05T00:00:00+00:00</published><updated>2019-03-05T00:00:00+00:00</updated><id>http://localhost:4000/posts/why-kurdish-language-processing-matters</id><content type="html" xml:base="http://localhost:4000/posts/why-kurdish-language-processing-matters.html">&lt;p&gt;Since the first time that I touched my home computer keyboard in 2001, I used to ask myself if it would be possible to make computer understand my mother language, &lt;a href=&quot;https://en.wikipedia.org/wiki/Kurdish_languages&quot; target=&quot;_blank&quot;&gt;Kurdish&lt;/a&gt;. Well, what I was imagining was definitely something limited to a Kurdish interface for Windows, particularly when I was going through the installation descriptions of &lt;a href=&quot;https://en.wikipedia.org/wiki/Return_to_Castle_Wolfenstein&quot; target=&quot;_blank&quot;&gt;Return to Castle Wolfenstein&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Mafia_(video_game)&quot; target=&quot;_blank&quot;&gt;Mafia: The City of Lost Heaven&lt;/a&gt;! Let alone the spontaneous questions that &lt;a href=&quot;https://en.wikipedia.org/wiki/Office_Assistant&quot; target=&quot;_blank&quot;&gt;Clippy&lt;/a&gt; was asking and how much I was curious to see the same messages in Kurdish.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
    &lt;img class=&quot;rounded mx-auto d-block&quot; src=&quot;http://localhost:4000/docs/images/clippy.png&quot; style=&quot;width:30%&quot; align=&quot;middle&quot; alt=&quot;Kurdish Clippy!&quot; /&gt;
    &lt;div class=&quot;card-body bg-light&quot;&gt;
        &lt;div class=&quot;card-text&quot;&gt;
            Me, when I was 9. “What if Clippy could ask “çon î” (how are you) in Kurdish?
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;In 2000s, there were a few application-based projects for introducing Kurdish to the computer world. For instance, a few Kurdish fonts were made based on the Persian and Arabic keyboards and the interface of some softwares were also translated into Kurdish. Since then, a lot of things have changed in the Information Technology (IT) world. Computers got smaller and more efficient, connections got faster than ever and subsequently, the world has become a smaller place. And still, the overall availability of electronic resources and processing tools for Kurdish is not to a satisfying extent. Kurdish is not just a language with a history that reflects the culture of its speakers. Indeed, it is the only element that has kept Kurds as a nation.&lt;/p&gt;

&lt;p&gt;In this post, I would like to address the importance of language technology for Kurdish language. Nowadays, with a plethora of (unstructured) online Kurdish resources and the recent progress in natural language processing and machine learning, I think that it is more feasible than ever to provide tools and resources for finally making Kurdish understandable by machine. I will also explain why I believe that the difficulty of processing Kurdish language is no more like the 2000s and there is currently a huge potential for Kurdish processing.&lt;/p&gt;

&lt;h2 id=&quot;what-is-natural-language-processing&quot;&gt;What is Natural Language Processing?&lt;/h2&gt;

&lt;p&gt;Formally speaking, Natural Language Processing (NLP) refers to the computer processing of &lt;em&gt;natural language&lt;/em&gt;: the language that we speak with. NLP is a part of the field of study which is called &lt;em&gt;language technology&lt;/em&gt;. If you are using a spell checker on your cell phone or your computer, or you use Siri or Google Assistant to ask about the nearest restaurant, then you have been already using some of the most common applications of NLP. Language technology is so present in nowadays life that most of us have been using them without even knowing about!&lt;/p&gt;

&lt;p&gt;Language technology is a primordial part of the Web. At our current pace (in 2019), we are producing 2.5 quintillion bytes of data each day, in other words 10&lt;sup&gt;18&lt;/sup&gt; bytes (&lt;a href=&quot;https://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read/#66bda05960ba&quot; target=&quot;_blank&quot;&gt;source&lt;/a&gt;), mostly unstructured data such as text, speech and so on. NLP technologies enable us to extract information from data and process the data for different applications.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
&lt;iframe width=&quot;700&quot; height=&quot;500&quot; align=&quot;middle&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; src=&quot;//plot.ly/~sinahm/4.embed?showlink=false&quot;&gt;&lt;/iframe&gt;
&lt;div class=&quot;card-body bg-light&quot;&gt;
    &lt;div class=&quot;card-text&quot;&gt;
      NLP total revenue by segments. Recreated based on the data from
        &lt;a href=&quot;https://www.tractica.com/newsroom/press-releases/natural-language-processing-market-to-reach-22-3-billion-by-2025/&quot; target=&quot;_blank&quot;&gt;Tractica&lt;/a&gt;.
    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;So, if you have a small or big business and you would like to know about the public opinion regarding your services, or you are a politician and would like to know what is happening around, or you are doing something for which human communication and interaction is important, then you will definitely need language technology.&lt;/p&gt;

&lt;h3 id=&quot;nlp-applications-a-few-examples-for-kurdish&quot;&gt;NLP applications: a few examples for Kurdish&lt;/h3&gt;

&lt;p&gt;Some of the applications of NLP are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Transliteration&lt;/strong&gt;: Kurdish is written in two scripts. The Latin-based script is used for writing in Kurmanji dialect, mostly spoken in Bakûr (means “north” in Kurdish and refers to the Kurdish regions in Turkey) and parts of Rojava (means “west” in Kurdish and refers to the Kurdish regions in Syria), while the Arabic-based script is used in Rojhełat (“east” in Kurdish, the Kurdish regions of Iran) and Basûr (“south” in Kurdish, the Kurdish regions of Iraq). A transliterator enables us to automatically convert one script to the other. As an example, “birayetî” (brotherhood in Kurdish) in the Latin-based script is transliterated as “برایەتی” in the Arabic-based script.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Morphological analysis&lt;/strong&gt;: Kurdish is an inflectional language. That is, a word can turn into a new word by adding a set of morphemes, such as suffixes and prefixes. For instance, “jinekan” (the women) is composed of “jin” (woman) and “ekan” (definite article added as a suffix to the noun). Detecting each morpheme is the task of morphological analyser. This is challenging, especially because of the huge number of derivational and inflectional morphemes in Kurdish. Another example, the Sorani word “dîtimin” which means “I saw them” is composed of “dîtim”, “I saw”, and “in” the object added as an accusative suffix.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Parts of Speech Tagging&lt;/strong&gt;: How do we know what is the grammatical role of each parts of this sentence : “Min gułekanim bon kird” (I smelled the flowers)? Well, that is what a part-of-speech tagger (POS tagger) does. For that case, a Kurdish PoS tagger will tell you that “min” is a pronoun, “gułekanim” is a definite noun and “bon kird” is the first singular person of the verb “bon kirdin” (to smell) in the past tense.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Machine translation&lt;/strong&gt;: This is maybe the most popular application of NLP. What if all dialects of Kurdish could be translated into other languages automatically? What is the equivalent of the Hawrami word “jerej” in Kurmanji and Sorani?[1] Machine translation takes care of the automatic translation using a parallel corpus. A corpus is a collection of text collected for a specific purpose. In a parallel corpus, the texts in two languages are aligned together. For instance, in a parallel corpus of Sorani Kurdish and English, for “&lt;em&gt;The distance between Sanandaj and Sulaymaniyah is 253 kilometers&lt;/em&gt;”, the following sentence is aligned: “&lt;em&gt;mewday nêwan Sine û Silêmanî 253 kîlomîtr e&lt;/em&gt;”. And now, imagine that in our corpus which contains thousands of parallel sentences, there are 100 sentences in which those words are used. That is where machine translation, based on statistical methods and more recently, neural network models, predicts that “Sine” means “Sanandaj” and “Silêmanî” means “Sulaymaniyah”, and even can translate sentences and more sophisticated texts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Speech recognition&lt;/strong&gt; Just try “OK google” on your Android phone, or “Hey, Siri” to activate your speech recogniser. Then talk as you talk with a real person and let the machine deal with it! That is what a speech recogniser does.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To discover more about NLP, &lt;a href=&quot;https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf&quot; target=&quot;_blank&quot;&gt;Jurafsky and Martin’s handbook in speech and language processing&lt;/a&gt; and  &lt;a href=&quot;https://www.cicling.org/2010/Vol46.pdf&quot; target=&quot;_blank&quot;&gt;Natural Language Processing and its Applications&lt;/a&gt; are two useful resources.&lt;/p&gt;

&lt;h2 id=&quot;challenges-of-kurdish-language-processing&quot;&gt;Challenges of Kurdish language processing&lt;/h2&gt;

&lt;p&gt;Kurdish is a less-resourced language. A less-resourced language is a language for which there is not enough language resources to be fully processed. In the following, I mention some of the main characteristics of Kurdish language which are also the main reasons that may explain the challenges in Kurdish language processing and why they have not been efficiently addressed yet.&lt;/p&gt;

&lt;h3 id=&quot;diversity-in-dialects&quot;&gt;Diversity in dialects&lt;/h3&gt;

&lt;p&gt;Having various dialects and sub-dialects, Kurdish is known as a dialect-rich language and is sometimes referred to as a &lt;a href=&quot;http://kurdish.humanities.manchester.ac.uk/wp-content/uploads/2017/07/PDF-Revisiting-Kurdish-dialect-geography.pdf&quot; target=&quot;_blank&quot;&gt;dialect continuum&lt;/a&gt;. This richness is intersting when you observe that what is called something in a village is called differently in the neighbourhood. As a personal observation, in &lt;a href=&quot;https://goo.gl/maps/hotbKuCa9Yz&quot; target=&quot;_blank&quot;&gt;Kêle Çermig&lt;/a&gt;, a village near Sanandaj in the Eastern Kurdistan, people use the word &lt;em&gt;amêjeng&lt;/em&gt; for yeast, while in &lt;a href=&quot;https://goo.gl/maps/VKPRG5REW6q&quot; target=&quot;_blank&quot;&gt;Syaseran&lt;/a&gt; it is called &lt;em&gt;amyan&lt;/em&gt;. Such differences are not limited to the vocabulary, but also to the phonology and the phonetics. Almost all the dialects and sub-dialects of Kurdish have something distinct in terms of pronunciation.&lt;/p&gt;

&lt;div class=&quot;card mb-3 text-center&quot;&gt;
&lt;h5 style=&quot;text-align:center;&quot;&gt;
&lt;iframe src=&quot;https://www.google.com/maps/embed?pb=!1m24!1m12!1m3!1d13191.505645251036!2d47.19145982556518!3d35.628163422931244!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!4m9!3e0!4m3!3m2!1d35.6333024!2d47.2136352!4m3!3m2!1d35.6285556!2d47.1856667!5e1!3m2!1sen!2sie!4v1552680935219&quot; width=&quot;600&quot; height=&quot;450&quot; frameborder=&quot;0&quot; style=&quot;border:0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/h5&gt;
&lt;div class=&quot;card-body bg-light&quot;&gt;
    &lt;div class=&quot;card-text&quot;&gt;
      Dialectal difference could even be observed between two neighbouring villages.
    &lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Having said that, the variety of the dialects adds a gap between the speakers  of the same language and to some extent, creates a kind of barrier in communication. Some believe that such diversities should be addressed by defining a &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_language&quot; target=&quot;_blank&quot;&gt;standard language&lt;/a&gt;. Defining a standard language for Kurdish has been a matter of debate without reaching a consensus.&lt;/p&gt;

&lt;h3 id=&quot;diversity-in-scripts&quot;&gt;Diversity in scripts&lt;/h3&gt;
&lt;p&gt;Due to historical and geological reasons, several scripts are used when it comes to Kurdish writing. Cyrillic, Arabo-Persian, Latin and even Armenian alphabets have been used to write Kurdish texts. In the recent years, the Kurdish Academy of Language has tried to unify those alphabets and present a unified alphabet for Kurdish called &lt;a href=&quot;http://kurdishacademy.org/2008/05/07/the-kurdish-unified-alphabet/&quot; target=&quot;_blank&quot;&gt;Yekgirtú&lt;/a&gt;. However, Yekgirtú does not seem to be as popular among the scholars nor the public; among all alphabets, the Arabo-Persian and the Latin alphabets are mostly used by Sorani and Kurmanji speakers, respectively. The following table shows those two alphabets in a comparative way.&lt;/p&gt;

&lt;table align=&quot;center&quot; class=&quot;table table-bordered table-hover table-condensed&quot;&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th title=&quot;Field #1&quot;&gt;Kurdish phonemes (IPA)&lt;/th&gt;
&lt;th title=&quot;Field #2&quot;&gt;Latin-based&lt;/th&gt;
&lt;th title=&quot;Field #3&quot;&gt;Yekgirtú&lt;/th&gt;
&lt;th title=&quot;Field #4&quot;&gt;Arabic-based&lt;/th&gt;
&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;[a:]&lt;/td&gt;
&lt;td&gt;A a&lt;/td&gt;
&lt;td&gt;A a&lt;/td&gt;
&lt;td&gt;ا&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[b]&lt;/td&gt;
&lt;td&gt;B b&lt;/td&gt;
&lt;td&gt;B b&lt;/td&gt;
&lt;td&gt;ب&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[t͡ʃ]&lt;/td&gt;
&lt;td&gt;Ç ç&lt;/td&gt;
&lt;td&gt;C c&lt;/td&gt;
&lt;td&gt;چ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[d͡ʒ]&lt;/td&gt;
&lt;td&gt;C c&lt;/td&gt;
&lt;td&gt;J j&lt;/td&gt;
&lt;td&gt;ج&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[d]&lt;/td&gt;
&lt;td&gt;D d&lt;/td&gt;
&lt;td&gt;D d&lt;/td&gt;
&lt;td&gt;د&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[æ]&lt;/td&gt;
&lt;td&gt;E e&lt;/td&gt;
&lt;td&gt;E e&lt;/td&gt;
&lt;td&gt;ه&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[eː ]&lt;/td&gt;
&lt;td&gt;Ê ê&lt;/td&gt;
&lt;td&gt;É é&lt;/td&gt;
&lt;td&gt;ێ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[f]&lt;/td&gt;
&lt;td&gt;F f&lt;/td&gt;
&lt;td&gt;F f&lt;/td&gt;
&lt;td&gt;ف&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[g]&lt;/td&gt;
&lt;td&gt;G g&lt;/td&gt;
&lt;td&gt;G g&lt;/td&gt;
&lt;td&gt;گ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[h]&lt;/td&gt;
&lt;td&gt;H h&lt;/td&gt;
&lt;td&gt;H h&lt;/td&gt;
&lt;td&gt;ھ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[I]&lt;/td&gt;
&lt;td&gt;I i&lt;/td&gt;
&lt;td&gt;I i&lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[i:]&lt;/td&gt;
&lt;td&gt;Î î&lt;/td&gt;
&lt;td&gt;Í í&lt;/td&gt;
&lt;td&gt;ى&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʒ]&lt;/td&gt;
&lt;td&gt;J j&lt;/td&gt;
&lt;td&gt;Jh jh&lt;/td&gt;
&lt;td&gt;ژ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[k]&lt;/td&gt;
&lt;td&gt;K k&lt;/td&gt;
&lt;td&gt;K k&lt;/td&gt;
&lt;td&gt;ک&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[l]&lt;/td&gt;
&lt;td&gt;L l&lt;/td&gt;
&lt;td&gt;L l&lt;/td&gt;
&lt;td&gt;ل&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ɬ]&lt;/td&gt;
&lt;td&gt;Ł ł&lt;/td&gt;
&lt;td&gt;Ll ll&lt;/td&gt;
&lt;td&gt;ڵ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[m]&lt;/td&gt;
&lt;td&gt;M m&lt;/td&gt;
&lt;td&gt;M m&lt;/td&gt;
&lt;td&gt;م&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[n]&lt;/td&gt;
&lt;td&gt;N n&lt;/td&gt;
&lt;td&gt;N n&lt;/td&gt;
&lt;td&gt;ن&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[oː ]&lt;/td&gt;
&lt;td&gt;O o&lt;/td&gt;
&lt;td&gt;O o&lt;/td&gt;
&lt;td&gt;ۆ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[p]&lt;/td&gt;
&lt;td&gt;P p&lt;/td&gt;
&lt;td&gt;P p&lt;/td&gt;
&lt;td&gt;پ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[q]&lt;/td&gt;
&lt;td&gt;Q q&lt;/td&gt;
&lt;td&gt;Q q&lt;/td&gt;
&lt;td&gt;ق&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ɾ]&lt;/td&gt;
&lt;td&gt;R r&lt;/td&gt;
&lt;td&gt;R r&lt;/td&gt;
&lt;td&gt;ر&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[r]&lt;/td&gt;
&lt;td&gt;Ř ř&lt;/td&gt;
&lt;td&gt;Rr rr&lt;/td&gt;
&lt;td&gt;ڕ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[s]&lt;/td&gt;
&lt;td&gt;S s&lt;/td&gt;
&lt;td&gt;S s&lt;/td&gt;
&lt;td&gt;س&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʃ]&lt;/td&gt;
&lt;td&gt;Ş ş&lt;/td&gt;
&lt;td&gt;Sh sh&lt;/td&gt;
&lt;td&gt;ش&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[t]&lt;/td&gt;
&lt;td&gt;T t&lt;/td&gt;
&lt;td&gt;T t&lt;/td&gt;
&lt;td&gt;ت&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʊ]&lt;/td&gt;
&lt;td&gt;U u&lt;/td&gt;
&lt;td&gt;U u&lt;/td&gt;
&lt;td&gt;و&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[u:]&lt;/td&gt;
&lt;td&gt;Û û&lt;/td&gt;
&lt;td&gt;Ú ú&lt;/td&gt;
&lt;td&gt;وو&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[v]&lt;/td&gt;
&lt;td&gt;Vv&lt;/td&gt;
&lt;td&gt;V v&lt;/td&gt;
&lt;td&gt;ڤ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[w]&lt;/td&gt;
&lt;td&gt;W w&lt;/td&gt;
&lt;td&gt;W w&lt;/td&gt;
&lt;td&gt;و&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[x]&lt;/td&gt;
&lt;td&gt;X x&lt;/td&gt;
&lt;td&gt;X x&lt;/td&gt;
&lt;td&gt;خ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[j]&lt;/td&gt;
&lt;td&gt;Y y&lt;/td&gt;
&lt;td&gt;Y y&lt;/td&gt;
&lt;td&gt;ى&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[z]&lt;/td&gt;
&lt;td&gt;Z z&lt;/td&gt;
&lt;td&gt;Z z&lt;/td&gt;
&lt;td&gt;ز&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ħ]&lt;/td&gt;
&lt;td&gt;Ḧ ḧ&lt;/td&gt;
&lt;td&gt;H&amp;#39;, h&amp;#39;&lt;/td&gt;
&lt;td&gt;ح&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʕ]&lt;/td&gt;
&lt;td&gt;Ë ë&lt;/td&gt;
&lt;td&gt;‘&lt;/td&gt;
&lt;td&gt;ع&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ɣ]&lt;/td&gt;
&lt;td&gt;Ẍ ẍ&lt;/td&gt;
&lt;td&gt;X&amp;#39;, x&amp;#39;&lt;/td&gt;
&lt;td&gt;غ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʉ:]&lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;td&gt;Ù ù&lt;/td&gt;
&lt;td&gt;ۊ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[γ]&lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;td&gt;ڎ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;[ʁ]&lt;/td&gt;
&lt;td&gt;Ğ ğ&lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;td bgcolor=&quot;#A9A9A9&quot;&gt; &lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h3 id=&quot;lack-of-standards&quot;&gt;Lack of standards&lt;/h3&gt;

&lt;p&gt;As discussed earlier, the diversity in dialects and scripts turns the richness of the language into a challenge. Such challenges are usually addressed by defining certain standards which do not exist for Kurdish yet. Defining a standard Kurdish language or Kurdish alphabet and deploying those standards require governmental actions and should be supported by scholars and Kurdish public.&lt;/p&gt;

&lt;h3 id=&quot;lack-of-resources&quot;&gt;Lack of resources&lt;/h3&gt;

&lt;p&gt;Electronic resources provide textual information about language and are essential for text mining in particular, and NLP in general. Those information can be collected and used as a &lt;a href=&quot;https://en.wikipedia.org/wiki/Text_corpus&quot; target=&quot;_blank&quot;&gt;text corpus&lt;/a&gt;. Fortunately, there are currently websites which are active in creating content in Kurdish, notably news agencies. Unfortunately, we still need more resources, especially expert-made ones such as lexicons and parallel corpora.&lt;/p&gt;

&lt;h3 id=&quot;lack-of-investment&quot;&gt;Lack of investment&lt;/h3&gt;

&lt;p&gt;Honestly, I believe that lack of investment should have been listed as the first reason of Kurdish remaining behind in NLP.&lt;/p&gt;

&lt;p&gt;A project needs to be funded to make a progress, which is unfortunately not the case for Kurdish-related projects. Due to the political constraints in Kurdistan, funding a Kurdish-related project is not a priority for the businesses. Even in the Southern Kurdistan, where there has been autonomy  (kind of) since 1992, there has not been a big advancement in this field.&lt;/p&gt;

&lt;p&gt;Such a difficulty seems to be the case of less-resourced languages. The following paragraph from the &lt;a href=&quot;http://ixa2.si.ehu.es/saltmil/index.php/en/news-mainmenu-287/36-news/89-lrec2010-saltmil-discussion.html&quot; target=&quot;_blank&quot;&gt;summary&lt;/a&gt; of the discussion on Less resourced languages and Language technology of the seventh international conference on Language Resources and Evaluation (LREC) explains how getting a project funded for a less-resourced language may be challenging:&lt;/p&gt;

&lt;div class=&quot;ml-3&quot;&gt;
&lt;p class=&quot;text-muted&quot;&gt;One of the problems that was underlined is the difficulties in convincing politicians to fund the creation of language resources (LR) for less-resourced languages (LRL). Per Langgård suggested that it would be necessary to build a scheme to assist developers to have success in that endeavour; Khalid Choukri said that even for large European languages it was also difficult to convince European Union politicians to fund R&amp;amp;D in the field, and that we needed to give politicians a larger picture and something they can sell to the media. Along the same lines, Igor Leturia mentioned that we should convince politicians that we do not only do research but that we produce products that politicians can see. &lt;/p&gt;

&lt;/div&gt;

&lt;h3 id=&quot;public-awareness&quot;&gt;Public awareness&lt;/h3&gt;

&lt;p&gt;In addition to the aforementioned factors, I should bitterly admit that there has been a kind of ignorance among the Kurds regarding their language and its correct usage as their formal language. I hope that my generation can promote using the power of Internet and make more people aware of the importance of language technology.&lt;/p&gt;

&lt;h2 id=&quot;what-to-do-then&quot;&gt;What to do then?&lt;/h2&gt;

&lt;h3 id=&quot;for-you-as-a-person&quot;&gt;For you as a person&lt;/h3&gt;

&lt;h4 id=&quot;use-utf-8-please&quot;&gt;Use UTF-8, &lt;mark&gt;Please&lt;/mark&gt;!&lt;/h4&gt;
&lt;p&gt;Each piece of text that you are typing is useful to make a language processable. Use a Kurdish keyboard and care about the correctness of what you type, as much as you can. Happily, there are currently many keyboards available on Google Play and iTunes which support Kurdish alphabets in UTF-8. (Take a look at &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.google.android.inputmethod.latin&amp;amp;hl=en_IE&quot; target=&quot;_blank&quot;&gt;Gboard - the Google Keyboard&lt;/a&gt; if you are an Android user).&lt;/p&gt;

&lt;h4 id=&quot;understand-the-value-of-data&quot;&gt;Understand the value of data&lt;/h4&gt;
&lt;p&gt;We are making information each day by sending messages to our friends and visiting social media. &lt;strong&gt;Try creating content in Kurdish&lt;/strong&gt;. &lt;a href=&quot;https://en.wikipedia.org/wiki/Blog&quot; target=&quot;_blank&quot;&gt;Blogging&lt;/a&gt; is a very interesting way to let others know about your ideas.&lt;/p&gt;

&lt;h4 id=&quot;be-creative-and-think-about-nlp&quot;&gt;Be creative and think about NLP&lt;/h4&gt;
&lt;p&gt;No matter what your expertise is, you can make a change in the current situation. If you are a Kurdish music fan, you can write the lyrics of the Kurdish songs and create a corpus for it. If you are interested in medical sciences, you can collect the terminology of your profession. If you are teaching a module related to computer science, NLP or computational linguistics, why not letting your students working on a Kurdish-related mini-project for their final project? And so on.&lt;/p&gt;

&lt;h4 id=&quot;research-in-kurdish-language-processing&quot;&gt;Research in Kurdish language processing&lt;/h4&gt;

&lt;p&gt;We need to do more research in Kurdish language processing. I strongly believe in the open data and open-source tools given the current situation of lack of investment.&lt;/p&gt;

&lt;h3 id=&quot;for-you-as-a-business-or-entrepreneur&quot;&gt;For you as a business or entrepreneur&lt;/h3&gt;

&lt;h4 id=&quot;invest&quot;&gt;Invest&lt;/h4&gt;

&lt;p&gt;Just like any other field in computer engineering, your business can make money by creating Kurdish language technology.&lt;/p&gt;

&lt;h4 id=&quot;fund-research-projects&quot;&gt;Fund research projects&lt;/h4&gt;

&lt;p&gt;Collaborate with academic research units and fund research projects related to Kurdish language processing. Taking a few interns per year can make a huge contribution to the field..&lt;/p&gt;

&lt;h4 id=&quot;promote-usage-of-tools-for-kurdish&quot;&gt;Promote usage of tools for Kurdish&lt;/h4&gt;

&lt;p&gt;News agencies, publication houses, authorities and all those who have a voice in the society, can promote the usage of tools which are made for Kurdish language processing.&lt;/p&gt;

&lt;h2 id=&quot;footnotes&quot;&gt;Footnotes&lt;/h2&gt;
&lt;p&gt;[1] “jerej” means “partridge“ in Hewrami Kurdish. In the Sorani Kurdish and in the Kurmanji Kurdish, “kew” and “vitik” are used respectively.&lt;/p&gt;

&lt;hr class=&quot;col-xs-12&quot; /&gt;

&lt;p&gt;Last updated on 26 March 2019.&lt;/p&gt;</content><author><name>Sina Ahmadi</name></author><category term="Kurdish" /><category term="NLP" /><category term="Kurdish language processing" /><category term="Less-resourced languages" /><summary type="html">Since the first time that I touched my home computer keyboard in 2001, I used to ask myself if it would be possible to make computer understand my mother language, Kurdish. Well, what I was imagining was definitely something limited to a Kurdish interface for Windows, particularly when I was going through the installation descriptions of Return to Castle Wolfenstein and Mafia: The City of Lost Heaven! Let alone the spontaneous questions that Clippy was asking and how much I was curious to see the same messages in Kurdish. Me, when I was 9. “What if Clippy could ask “çon î” (how are you) in Kurdish? In 2000s, there were a few application-based projects for introducing Kurdish to the computer world. For instance, a few Kurdish fonts were made based on the Persian and Arabic keyboards and the interface of some softwares were also translated into Kurdish. Since then, a lot of things have changed in the Information Technology (IT) world. Computers got smaller and more efficient, connections got faster than ever and subsequently, the world has become a smaller place. And still, the overall availability of electronic resources and processing tools for Kurdish is not to a satisfying extent. Kurdish is not just a language with a history that reflects the culture of its speakers. Indeed, it is the only element that has kept Kurds as a nation. In this post, I would like to address the importance of language technology for Kurdish language. Nowadays, with a plethora of (unstructured) online Kurdish resources and the recent progress in natural language processing and machine learning, I think that it is more feasible than ever to provide tools and resources for finally making Kurdish understandable by machine. I will also explain why I believe that the difficulty of processing Kurdish language is no more like the 2000s and there is currently a huge potential for Kurdish processing. What is Natural Language Processing? Formally speaking, Natural Language Processing (NLP) refers to the computer processing of natural language: the language that we speak with. NLP is a part of the field of study which is called language technology. If you are using a spell checker on your cell phone or your computer, or you use Siri or Google Assistant to ask about the nearest restaurant, then you have been already using some of the most common applications of NLP. Language technology is so present in nowadays life that most of us have been using them without even knowing about! Language technology is a primordial part of the Web. At our current pace (in 2019), we are producing 2.5 quintillion bytes of data each day, in other words 1018 bytes (source), mostly unstructured data such as text, speech and so on. NLP technologies enable us to extract information from data and process the data for different applications. NLP total revenue by segments. Recreated based on the data from Tractica. So, if you have a small or big business and you would like to know about the public opinion regarding your services, or you are a politician and would like to know what is happening around, or you are doing something for which human communication and interaction is important, then you will definitely need language technology. NLP applications: a few examples for Kurdish Some of the applications of NLP are: Transliteration: Kurdish is written in two scripts. The Latin-based script is used for writing in Kurmanji dialect, mostly spoken in Bakûr (means “north” in Kurdish and refers to the Kurdish regions in Turkey) and parts of Rojava (means “west” in Kurdish and refers to the Kurdish regions in Syria), while the Arabic-based script is used in Rojhełat (“east” in Kurdish, the Kurdish regions of Iran) and Basûr (“south” in Kurdish, the Kurdish regions of Iraq). A transliterator enables us to automatically convert one script to the other. As an example, “birayetî” (brotherhood in Kurdish) in the Latin-based script is transliterated as “برایەتی” in the Arabic-based script. Morphological analysis: Kurdish is an inflectional language. That is, a word can turn into a new word by adding a set of morphemes, such as suffixes and prefixes. For instance, “jinekan” (the women) is composed of “jin” (woman) and “ekan” (definite article added as a suffix to the noun). Detecting each morpheme is the task of morphological analyser. This is challenging, especially because of the huge number of derivational and inflectional morphemes in Kurdish. Another example, the Sorani word “dîtimin” which means “I saw them” is composed of “dîtim”, “I saw”, and “in” the object added as an accusative suffix. Parts of Speech Tagging: How do we know what is the grammatical role of each parts of this sentence : “Min gułekanim bon kird” (I smelled the flowers)? Well, that is what a part-of-speech tagger (POS tagger) does. For that case, a Kurdish PoS tagger will tell you that “min” is a pronoun, “gułekanim” is a definite noun and “bon kird” is the first singular person of the verb “bon kirdin” (to smell) in the past tense. Machine translation: This is maybe the most popular application of NLP. What if all dialects of Kurdish could be translated into other languages automatically? What is the equivalent of the Hawrami word “jerej” in Kurmanji and Sorani?[1] Machine translation takes care of the automatic translation using a parallel corpus. A corpus is a collection of text collected for a specific purpose. In a parallel corpus, the texts in two languages are aligned together. For instance, in a parallel corpus of Sorani Kurdish and English, for “The distance between Sanandaj and Sulaymaniyah is 253 kilometers”, the following sentence is aligned: “mewday nêwan Sine û Silêmanî 253 kîlomîtr e”. And now, imagine that in our corpus which contains thousands of parallel sentences, there are 100 sentences in which those words are used. That is where machine translation, based on statistical methods and more recently, neural network models, predicts that “Sine” means “Sanandaj” and “Silêmanî” means “Sulaymaniyah”, and even can translate sentences and more sophisticated texts. Speech recognition Just try “OK google” on your Android phone, or “Hey, Siri” to activate your speech recogniser. Then talk as you talk with a real person and let the machine deal with it! That is what a speech recogniser does. To discover more about NLP, Jurafsky and Martin’s handbook in speech and language processing and Natural Language Processing and its Applications are two useful resources. Challenges of Kurdish language processing Kurdish is a less-resourced language. A less-resourced language is a language for which there is not enough language resources to be fully processed. In the following, I mention some of the main characteristics of Kurdish language which are also the main reasons that may explain the challenges in Kurdish language processing and why they have not been efficiently addressed yet. Diversity in dialects Having various dialects and sub-dialects, Kurdish is known as a dialect-rich language and is sometimes referred to as a dialect continuum. This richness is intersting when you observe that what is called something in a village is called differently in the neighbourhood. As a personal observation, in Kêle Çermig, a village near Sanandaj in the Eastern Kurdistan, people use the word amêjeng for yeast, while in Syaseran it is called amyan. Such differences are not limited to the vocabulary, but also to the phonology and the phonetics. Almost all the dialects and sub-dialects of Kurdish have something distinct in terms of pronunciation. Dialectal difference could even be observed between two neighbouring villages. Having said that, the variety of the dialects adds a gap between the speakers of the same language and to some extent, creates a kind of barrier in communication. Some believe that such diversities should be addressed by defining a standard language. Defining a standard language for Kurdish has been a matter of debate without reaching a consensus. Diversity in scripts Due to historical and geological reasons, several scripts are used when it comes to Kurdish writing. Cyrillic, Arabo-Persian, Latin and even Armenian alphabets have been used to write Kurdish texts. In the recent years, the Kurdish Academy of Language has tried to unify those alphabets and present a unified alphabet for Kurdish called Yekgirtú. However, Yekgirtú does not seem to be as popular among the scholars nor the public; among all alphabets, the Arabo-Persian and the Latin alphabets are mostly used by Sorani and Kurmanji speakers, respectively. The following table shows those two alphabets in a comparative way. Kurdish phonemes (IPA) Latin-based Yekgirtú Arabic-based [a:] A a A a ا [b] B b B b ب [t͡ʃ] Ç ç C c چ [d͡ʒ] C c J j ج [d] D d D d د [æ] E e E e ه [eː ] Ê ê É é ێ [f] F f F f ف [g] G g G g گ [h] H h H h ھ [I] I i I i [i:] Î î Í í ى [ʒ] J j Jh jh ژ [k] K k K k ک [l] L l L l ل [ɬ] Ł ł Ll ll ڵ [m] M m M m م [n] N n N n ن [oː ] O o O o ۆ [p] P p P p پ [q] Q q Q q ق [ɾ] R r R r ر [r] Ř ř Rr rr ڕ [s] S s S s س [ʃ] Ş ş Sh sh ش [t] T t T t ت [ʊ] U u U u و [u:] Û û Ú ú وو [v] Vv V v ڤ [w] W w W w و [x] X x X x خ [j] Y y Y y ى [z] Z z Z z ز [ħ] Ḧ ḧ H&amp;#39;, h&amp;#39; ح [ʕ] Ë ë ‘ ع [ɣ] Ẍ ẍ X&amp;#39;, x&amp;#39; غ [ʉ:] Ù ù ۊ [γ] ڎ [ʁ] Ğ ğ Lack of standards As discussed earlier, the diversity in dialects and scripts turns the richness of the language into a challenge. Such challenges are usually addressed by defining certain standards which do not exist for Kurdish yet. Defining a standard Kurdish language or Kurdish alphabet and deploying those standards require governmental actions and should be supported by scholars and Kurdish public. Lack of resources Electronic resources provide textual information about language and are essential for text mining in particular, and NLP in general. Those information can be collected and used as a text corpus. Fortunately, there are currently websites which are active in creating content in Kurdish, notably news agencies. Unfortunately, we still need more resources, especially expert-made ones such as lexicons and parallel corpora. Lack of investment Honestly, I believe that lack of investment should have been listed as the first reason of Kurdish remaining behind in NLP. A project needs to be funded to make a progress, which is unfortunately not the case for Kurdish-related projects. Due to the political constraints in Kurdistan, funding a Kurdish-related project is not a priority for the businesses. Even in the Southern Kurdistan, where there has been autonomy (kind of) since 1992, there has not been a big advancement in this field. Such a difficulty seems to be the case of less-resourced languages. The following paragraph from the summary of the discussion on Less resourced languages and Language technology of the seventh international conference on Language Resources and Evaluation (LREC) explains how getting a project funded for a less-resourced language may be challenging: One of the problems that was underlined is the difficulties in convincing politicians to fund the creation of language resources (LR) for less-resourced languages (LRL). Per Langgård suggested that it would be necessary to build a scheme to assist developers to have success in that endeavour; Khalid Choukri said that even for large European languages it was also difficult to convince European Union politicians to fund R&amp;amp;D in the field, and that we needed to give politicians a larger picture and something they can sell to the media. Along the same lines, Igor Leturia mentioned that we should convince politicians that we do not only do research but that we produce products that politicians can see. Public awareness In addition to the aforementioned factors, I should bitterly admit that there has been a kind of ignorance among the Kurds regarding their language and its correct usage as their formal language. I hope that my generation can promote using the power of Internet and make more people aware of the importance of language technology. What to do then? For you as a person Use UTF-8, Please! Each piece of text that you are typing is useful to make a language processable. Use a Kurdish keyboard and care about the correctness of what you type, as much as you can. Happily, there are currently many keyboards available on Google Play and iTunes which support Kurdish alphabets in UTF-8. (Take a look at Gboard - the Google Keyboard if you are an Android user). Understand the value of data We are making information each day by sending messages to our friends and visiting social media. Try creating content in Kurdish. Blogging is a very interesting way to let others know about your ideas. Be creative and think about NLP No matter what your expertise is, you can make a change in the current situation. If you are a Kurdish music fan, you can write the lyrics of the Kurdish songs and create a corpus for it. If you are interested in medical sciences, you can collect the terminology of your profession. If you are teaching a module related to computer science, NLP or computational linguistics, why not letting your students working on a Kurdish-related mini-project for their final project? And so on. Research in Kurdish language processing We need to do more research in Kurdish language processing. I strongly believe in the open data and open-source tools given the current situation of lack of investment. For you as a business or entrepreneur Invest Just like any other field in computer engineering, your business can make money by creating Kurdish language technology. Fund research projects Collaborate with academic research units and fund research projects related to Kurdish language processing. Taking a few interns per year can make a huge contribution to the field.. Promote usage of tools for Kurdish News agencies, publication houses, authorities and all those who have a voice in the society, can promote the usage of tools which are made for Kurdish language processing. Footnotes [1] “jerej” means “partridge“ in Hewrami Kurdish. In the Sorani Kurdish and in the Kurmanji Kurdish, “kew” and “vitik” are used respectively. Last updated on 26 March 2019.</summary></entry></feed>